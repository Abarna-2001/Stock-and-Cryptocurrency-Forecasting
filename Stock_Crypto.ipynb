{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13450819-241d-4d9b-9894-b9c62e4ffad5",
   "metadata": {},
   "source": [
    "# Hybrid Machine Learning Approach for Stock and Cryptocurrency Forecasting \n",
    "\n",
    "---\n",
    "\n",
    "## Notebook purpose\n",
    "This notebook documents the full implementation of my dissertation project. The goal is to build and evaluate machine learning and hybrid models to predict next-day price movement trends in:\n",
    "\n",
    "- **Stock market:** Apple Inc. (AAPL)  \n",
    "- **Cryptocurrency market:** Bitcoin (BTC-USD)\n",
    "\n",
    "To predict the next-day closing price and evaluate trend prediction using Directional Accuracy (whether the model correctly predicts up/down movement).\n",
    "\n",
    "---\n",
    "\n",
    "## Research aim\n",
    "To investigate whether a hybrid machine learning approach (Random Forest feature selection + LSTM sequence modelling) can improve prediction performance for both stock and cryptocurrency market trends compared to strong baseline models.\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "This notebook investigates whether a hybrid machine learning approach improves next-day price prediction for:\n",
    "- Stock: AAPL\n",
    "- Cryptocurrency: BTC-USD\n",
    "\n",
    "1. Collect daily OHLCV price data from 2018 to 2024 for AAPL and BTC-USD from open-source sources (Yahoo Finance).  \n",
    "2. Clean and validate the dataset (missing values, duplicates, date range checks).  \n",
    "3. Engineer interpretable technical indicators (SMA, EMA, RSI, MACD, Bollinger Bands, returns, volatility).  \n",
    "4. Train Regression and baseline models (Linear regression, Ridge regression, Support vector Regression, Random Forest and XGBoost).  \n",
    "5. Train sequence model (LSTM) and a hybrid RF→LSTM pipeline.  \n",
    "6. Evaluate models using MAE, RMSE, MAPE and Directional Accuracy.  \n",
    "7. Produce diagnostic plots and a results summary table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48ead0-a727-4c2a-b071-bb91f0dc8eb4",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Reproducibility\n",
    "\n",
    "This section defines the computational environment used to develop and evaluate all models in this project. Ensuring a stable and reproducible environment is essential for research, particularly when working with machine learning and deep learning frameworks.\n",
    "\n",
    "The notebook is designed to run in a controlled Python environment with consistent library versions. This helps to minimise variability in results caused by software updates or dependency conflicts.\n",
    "\n",
    "Key reproducibility measures include:\n",
    "- Use of a fixed Python version and well-established libraries\n",
    "- Explicit imports of all required packages\n",
    "- Setting random seeds where applicable to reduce stochastic variation\n",
    "- Using a fixed historical date range for all experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96935ff-ceb7-4a48-94ef-e6f893202170",
   "metadata": {},
   "source": [
    "## Python Packages and Libraries\n",
    "\n",
    "The following Python libraries were used throughout the project. \n",
    "\n",
    "| Package | Purpose in the Project |\n",
    "|-------|------------------------|\n",
    "| **numpy** | Numerical computing and efficient array operations |\n",
    "| **pandas** | Data manipulation, time-series handling and preprocessing |\n",
    "| **matplotlib** | Visualisation of price trends, predictions and diagnostics |\n",
    "| **scikit-learn** | Classical machine learning models, preprocessing and evaluation metrics |\n",
    "| **yfinance** | Retrieval of historical stock and cryptocurrency data from Yahoo Finance |\n",
    "| **tensorflow** | Implementation and training of the LSTM deep learning model |\n",
    "| **seaborn**  | Enhanced statistical visualisations |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae830d7-7f2b-4d79-bfcc-9f787c0500b1",
   "metadata": {},
   "source": [
    "### 1.1 Project Overview\n",
    "\n",
    "This project investigates the application of hybrid machine learning models for predicting stock and cryptocurrency prices. Specifically, it focuses on Apple Inc.(AAPL) as a representative stock and Bitcoin (BTC-USD) as a representative cryptocurrency.\n",
    "\n",
    "The primary objective is to design, implement and evaluate a hybrid modelling framework that combines tree-based machine learning models with deep learning techniques to capture both nonlinear feature relationships and temporal dependencies in financial time-series data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8cdea-72dd-4331-bbb3-bc2b0c406024",
   "metadata": {},
   "source": [
    "### 1.2 Imports and configuration\n",
    "\n",
    "This section imports all required Python libraries and dependencies used throughout\n",
    "the notebook. The environment is configured to ensure reproducibility and\n",
    "compatibility with the implemented machine learning and deep learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0dc08c-8988-4e4f-8a5a-fd58a6855d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "#        Imports\n",
    "# ==============================\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Yahoo Finance data\n",
    "import yfinance as yf\n",
    "\n",
    "# xgboost essentials\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# TensorFlow essentials\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# scikit-learn essentials\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c90482-480f-454a-9591-1a7f941dc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Reproducibility\n",
    "# ------------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# TensorFlow (for LSTM)\n",
    "TF_AVAILABLE = True\n",
    "try:\n",
    "    tf.random.set_seed(SEED)\n",
    "except Exception as e:\n",
    "    TF_AVAILABLE = False\n",
    "    print(\"[WARN] TensorFlow not available. LSTM sections will be skipped.\", str(e)[:160])\n",
    "\n",
    "# XGBoost baseline\n",
    "XGB_AVAILABLE = True\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception as e:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"[WARN] XGBoost not available. XGB baseline will be skipped.\", str(e)[:160])\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Project folders\n",
    "# ------------------------------\n",
    "DATA_DIR = \"data\"\n",
    "FIG_DIR = \"figures\"\n",
    "OUT_DIR = \"outputs\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Project settings\n",
    "# ------------------------------\n",
    "START_DATE = \"2018-01-01\"\n",
    "END_DATE = \"2024-12-31\"  \n",
    "\n",
    "STOCK_TICKER = \"AAPL\"\n",
    "CRYPTO_TICKER = \"BTC-USD\"\n",
    "\n",
    "LOOKBACK_WINDOW = 30     # LSTM input sequence length\n",
    "TEST_SIZE = 0.20         # 80/20 holdout split (chronological)\n",
    "SAVE_FIGS = True         # save figures to figures/ folder\n",
    "\n",
    "print(\"Environment ready.\")\n",
    "print(\"TensorFlow available:\", TF_AVAILABLE)\n",
    "print(\"XGBoost available:\", XGB_AVAILABLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c2d694-75e4-4871-81bb-5c1cc93ce633",
   "metadata": {},
   "source": [
    "### Helper function to save plots and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fba34c-cb0c-4a2f-bfd1-f8b1de9a5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefig(filename: str):\n",
    "    \"\"\"Save current matplotlib figure to the figures folder (300 dpi).\"\"\"\n",
    "    if SAVE_FIGS:\n",
    "        path = os.path.join(FIG_DIR, filename)\n",
    "        plt.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"[Saved figure] {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642fe5d-83d3-4518-89a5-f7f29aa933ef",
   "metadata": {},
   "source": [
    "## 2. Data collection and initial validation\n",
    "\n",
    "This stage focuses on collecting reliable historical price data required for model development.\n",
    "Daily price data is retrieved for one stock market asset and one cryptocurrency asset:\n",
    "\n",
    "- **Stock:** Apple Inc. (AAPL)\n",
    "- **Cryptocurrency:** Bitcoin (BTC-USD)\n",
    "\n",
    "The data is sourced from *Yahoo Finance*, accessed programmatically using the `yfinance` Python library.\n",
    "Yahoo Finance provides adjusted daily OHLCV (Open, High, Low, Close, Volume) data.\n",
    "\n",
    "To support transparency and reproducibility:\n",
    "- Raw datasets are stored locally as CSV files.\n",
    "- Basic data quality checks are performed immediately after download.\n",
    "- The date range is fixed to maintain consistency across all experiments.\n",
    "\n",
    "The goal is to validate that the raw data is complete, consistent and suitable for further analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faa0bd-86d7-4cf6-8dc8-f585546fcf4b",
   "metadata": {},
   "source": [
    "### 2.1 Data Collection\n",
    "\n",
    "Historical price data for AAPL (stock) and BTC-USD (cryptocurrency) are collected using the Yahoo Finance API. The dataset spans multiple years from 2018 to 2024 to capture different market conditions, including stable, volatile and recovery periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f4166-e8a3-4974-812e-27b3a07964ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 2.1 Download historical OHLCV data\n",
    "# ==================================\n",
    "\n",
    "def download_yahoo_data(ticker: str, start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downloads daily OHLCV data from Yahoo Finance.\n",
    "    Returns a cleaned DataFrame with a Date column.\n",
    "    \"\"\"\n",
    "    df = yf.download(ticker, start=start, end=end, progress=False)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data returned for ticker: {ticker}\")\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df[\"Ticker\"] = ticker\n",
    "    return df\n",
    "\n",
    "\n",
    "# Download stock and crypto data\n",
    "stock_df = download_yahoo_data(STOCK_TICKER, START_DATE, END_DATE)\n",
    "crypto_df = download_yahoo_data(CRYPTO_TICKER, START_DATE, END_DATE)\n",
    "\n",
    "# Save raw datasets for reproducibility\n",
    "stock_df.to_csv(os.path.join(DATA_DIR, f\"{STOCK_TICKER}_raw.csv\"), index=False)\n",
    "crypto_df.to_csv(os.path.join(DATA_DIR, f\"{CRYPTO_TICKER}_raw.csv\"), index=False)\n",
    "\n",
    "print(\"Stock data shape:\", stock_df.shape)\n",
    "print(\"Crypto data shape:\", crypto_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b56a5f-27a2-48ea-a597-3c511f872b47",
   "metadata": {},
   "source": [
    "### 2.2 Data Quality Assessment\n",
    "\n",
    "This section performs an initial inspection of the raw datasets to assess dataquality. Checks include dataset dimensions, missing values, duplicate records and date ranges to ensure the data is suitable for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd5fb1-f1a0-40c3-b5fa-004b01920639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 2.2 Data quality \n",
    "# =======================\n",
    "\n",
    "def data_quality_report(df: pd.DataFrame, name: str):\n",
    "    \"\"\"\n",
    "    Prints a simple data quality report for a dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"DATA QUALITY REPORT: {name}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Number of rows:\", len(df))\n",
    "    print(\"Number of columns:\", df.shape[1])\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nDuplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "    if \"Date\" in df.columns:\n",
    "        print(\"\\nDate range:\")\n",
    "        print(\"Start:\", df[\"Date\"].min())\n",
    "        print(\"End:\", df[\"Date\"].max())\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "data_quality_report(stock_df, \"AAPL (Stock)\")\n",
    "data_quality_report(crypto_df, \"BTC-USD (Cryptocurrency)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62cce98-2778-4151-a892-df7163da5eeb",
   "metadata": {},
   "source": [
    "### 2.3 Exploratory Price Trend Visualization\n",
    "\n",
    "This section visualizes the historical closing price trends for both AAPL and BTC-USD. The purpose is to gain an initial understanding of price behaviour, volatility patterns and long-term trends in stock and cryptocurrency markets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913e6ef-7dd4-41b1-804b-dd6440f5515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 2.3 Initial price trend visualisation\n",
    "# ==================================\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(stock_df[\"Date\"], stock_df[\"Close\"], label=\"AAPL (Stock)\")\n",
    "plt.plot(crypto_df[\"Date\"], crypto_df[\"Close\"], label=\"BTC-USD (Crypto)\")\n",
    "plt.title(\"Closing Price Trends (2018–2024)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "savefig(\"fig_raw_price_trends.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f6cf2-8c17-4259-8765-b95dda78ff5b",
   "metadata": {},
   "source": [
    "## 3. Data alignment and pre-processing\n",
    "\n",
    "Financial time-series data must be aligned before any modelling can take place.\n",
    "Stock markets operate only on business days, while cryptocurrency markets trade continuously.\n",
    "As a result, stock and cryptocurrency datasets differ in both length and calendar structure.\n",
    "\n",
    "To ensure consistency:\n",
    "- Both datasets are aligned using a shared date index.\n",
    "- Missing dates resulting from non-trading days are handled carefully.\n",
    "- Forward-filling is applied to preserve the most recent available market information.\n",
    "- The aligned dataset is converted into a wide format, enabling unified feature engineering.\n",
    "\n",
    "This step ensures that all models are trained on a consistent temporal representation,\n",
    "which is critical for valid comparison between stock and cryptocurrency predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee61ef-7af4-4d6b-acb8-dec20482c0e0",
   "metadata": {},
   "source": [
    "### 3.1 Date Alignment\n",
    "\n",
    "Stock and cryptocurrency markets operate on different trading schedules. This section aligns the datasets by date to ensure consistency when analysing\n",
    "cross-market relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddddb0b-0c78-4b85-8a87-35ae4a34317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 3.1 Date formatting and sorting\n",
    "# ==================================\n",
    "\n",
    "stock_df[\"Date\"] = pd.to_datetime(stock_df[\"Date\"])\n",
    "crypto_df[\"Date\"] = pd.to_datetime(crypto_df[\"Date\"])\n",
    "\n",
    "stock_df = stock_df.sort_values(\"Date\")\n",
    "crypto_df = crypto_df.sort_values(\"Date\")\n",
    "\n",
    "print(\"Stock date range:\", stock_df[\"Date\"].min(), \"to\", stock_df[\"Date\"].max())\n",
    "print(\"Crypto date range:\", crypto_df[\"Date\"].min(), \"to\", crypto_df[\"Date\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d49a2-1958-4b48-8eb1-eec21f327d77",
   "metadata": {},
   "source": [
    "### 3.2 Combined Dataset Construction\n",
    "\n",
    "This section merges the aligned stock and cryptocurrency datasets into a single time-indexed dataset. The combined dataset enables joint feature engineering and cross-market analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df0476-df6f-4455-a5bd-a8be4ef1b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 3.2 Align stock and crypto data\n",
    "# ==================================\n",
    "\n",
    "def align_time_series(stock_df: pd.DataFrame, crypto_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aligns stock and cryptocurrency data on a common date index\n",
    "    and returns a wide-format DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    stock_series = stock_df.set_index(\"Date\")[[\"Close\", \"Volume\"]]\n",
    "    crypto_series = crypto_df.set_index(\"Date\")[[\"Close\", \"Volume\"]]\n",
    "\n",
    "    stock_series.columns = [\"Close_AAPL\", \"Volume_AAPL\"]\n",
    "    crypto_series.columns = [\"Close_BTC\", \"Volume_BTC\"]\n",
    "\n",
    "    # Outer join to include all dates\n",
    "    combined = pd.concat([stock_series, crypto_series], axis=1)\n",
    "\n",
    "    # Forward-fill missing values caused by non-trading days\n",
    "    combined = combined.ffill()\n",
    "    return combined\n",
    "\n",
    "aligned_df = align_time_series(stock_df, crypto_df)\n",
    "\n",
    "print(\"Aligned dataset shape:\", aligned_df.shape)\n",
    "aligned_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79cf4a-afec-4b8a-9f32-9070b75b359b",
   "metadata": {},
   "source": [
    "### 3.3 Data Quality Check After Alignment\n",
    "\n",
    "Following dataset alignment, additional data quality checks are performed to identify missing values or inconsistencies introduced during the merging process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bae401-9e07-40c1-9d4f-1c06e6a23a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 3.3 Post-alignment data quality\n",
    "# ==================================\n",
    "\n",
    "data_quality_report(aligned_df.reset_index(), \"Aligned stock-crypto dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b63f1-7719-410d-8bf7-0c9965097c5e",
   "metadata": {},
   "source": [
    "### 3.4 Aligned Price Visualization\n",
    "\n",
    "This section visualizes the aligned closing prices for AAPL and BTC-USD to confirm that the datasets are synchronised correctly after preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bce4c5-1b98-4816-9ef2-533ebe15c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 3.4 Visual validation of alignment\n",
    "# ==================================\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(aligned_df.index, aligned_df[\"Close_AAPL\"], label=\"AAPL (Aligned)\")\n",
    "plt.plot(aligned_df.index, aligned_df[\"Close_BTC\"], label=\"BTC-USD (Aligned)\")\n",
    "plt.title(\"Aligned Closing Prices (Post Pre-processing)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "savefig(\"aligned_price_trends.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adda135-c655-4dce-9d94-57fd7fe1d8d2",
   "metadata": {},
   "source": [
    "### 3.5 Feature Correlation Analysis\n",
    "\n",
    "A correlation heatmap is generated to examine relationships between stock and cryptocurrency features. This analysis provides insight into potential\n",
    "interdependencies across markets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61d134-d4af-458c-ba9d-9f015f4d9d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 3.5 Remove initial non-trading day\n",
    "# ==================================\n",
    "\n",
    "aligned_df = aligned_df.dropna()\n",
    "\n",
    "data_quality_report(aligned_df.reset_index(), \"Aligned dataset (post-cleaning)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fabc1-7029-4691-ae83-ba6d1b4eb140",
   "metadata": {},
   "source": [
    "## 4. Feature engineering\n",
    "\n",
    "Raw price data alone is insufficient for effective financial prediction.Machine learning models benefit from engineered features that capture:\n",
    "\n",
    "- Market trends\n",
    "- Momentum\n",
    "- Volatility\n",
    "- Short-term and medium-term price behaviour\n",
    "\n",
    "In this section, a set of widely used and technical indicators are constructed for both assets.\n",
    "\n",
    "The selected features are:\n",
    "- Simple Moving Average (SMA)\n",
    "- Exponential Moving Average (EMA)\n",
    "- Daily returns\n",
    "- Rolling volatility\n",
    "- Relative Strength Index (RSI)\n",
    "- Bollinger Bands\n",
    "- MACD (trend momentum indicator)\n",
    "\n",
    "All features are computed using only historical data, avoiding data leakage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170f39cc-56a7-4aa2-9e14-2a578df5b443",
   "metadata": {},
   "source": [
    "### 4.1 Feature Engineering\n",
    "\n",
    "This section generates technical indicators for both AAPL and BTC-USD, including moving averages, volatility measures, momentum indicators and trend-based features. These engineered features enhance the models ability to capture market dynamics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4fa3f-9596-4ae3-a879-93e132d6ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 4.1 Technical indicator functions\n",
    "# ==================================\n",
    "\n",
    "def add_sma(df, col, window):\n",
    "    df[f\"{col}_SMA_{window}\"] = df[col].rolling(window).mean()\n",
    "    return df\n",
    "\n",
    "def add_ema(df, col, span):\n",
    "    df[f\"{col}_EMA_{span}\"] = df[col].ewm(span=span, adjust=False).mean()\n",
    "    return df\n",
    "\n",
    "def add_returns(df, col):\n",
    "    df[f\"{col}_RET\"] = df[col].pct_change()\n",
    "    return df\n",
    "\n",
    "def add_volatility(df, col, window=10):\n",
    "    df[f\"{col}_VOL_{window}\"] = df[col].pct_change().rolling(window).std()\n",
    "    return df\n",
    "\n",
    "def add_rsi(df, col, window=14):\n",
    "    delta = df[col].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window).mean()\n",
    "    avg_loss = loss.rolling(window).mean()\n",
    "    rs = avg_gain / (avg_loss + 1e-9)\n",
    "    df[f\"{col}_RSI_{window}\"] = 100 - (100 / (1 + rs))\n",
    "    return df\n",
    "\n",
    "def add_bollinger(df, col, window=20, num_std=2):\n",
    "    mid = df[col].rolling(window).mean()\n",
    "    std = df[col].rolling(window).std()\n",
    "    df[f\"{col}_BB_MID\"] = mid\n",
    "    df[f\"{col}_BB_UP\"] = mid + num_std * std\n",
    "    df[f\"{col}_BB_LOW\"] = mid - num_std * std\n",
    "    return df\n",
    "\n",
    "def add_macd(df, col):\n",
    "    ema_fast = df[col].ewm(span=12, adjust=False).mean()\n",
    "    ema_slow = df[col].ewm(span=26, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    df[f\"{col}_MACD\"] = macd\n",
    "    df[f\"{col}_MACD_SIGNAL\"] = signal\n",
    "    df[f\"{col}_MACD_HIST\"] = macd - signal\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52af8cc-6d1a-45ed-b38e-25ca75823247",
   "metadata": {},
   "source": [
    "### 4.2 Validation of Engineered Features\n",
    "\n",
    "After feature engineering, data quality checks are repeated to ensure that all newly created features are valid and free from missing values or inconsistencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d658181-dd7f-4fb0-a018-1ba3055e577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 4.2 Build feature dataset\n",
    "# ==================================\n",
    "\n",
    "features_df = aligned_df.copy()\n",
    "\n",
    "targets = [\"Close_AAPL\", \"Close_BTC\"]\n",
    "\n",
    "for t in targets:\n",
    "    features_df = add_sma(features_df, t, 5)\n",
    "    features_df = add_sma(features_df, t, 10)\n",
    "    features_df = add_ema(features_df, t, 10)\n",
    "    features_df = add_returns(features_df, t)\n",
    "    features_df = add_volatility(features_df, t, 10)\n",
    "    features_df = add_rsi(features_df, t, 14)\n",
    "    features_df = add_bollinger(features_df, t)\n",
    "    features_df = add_macd(features_df, t)\n",
    "\n",
    "# Remove rows created by rolling calculations\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "data_quality_report(features_df.reset_index(), \"Feature-engineered dataset\")\n",
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a582efcb-f806-429a-9a87-8e1dbd0809a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 4.3 Feature correlation analysis\n",
    "# ==================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(9, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    features_df.corr(),\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    linewidths=0.3,\n",
    "    cbar_kws={\"label\": \"Correlation\"}\n",
    ")\n",
    "\n",
    "plt.title(\"Feature Correlation Heatmap\", fontsize=9)\n",
    "plt.tight_layout()\n",
    "savefig(\"feature_correlation.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f914d0-0d24-4c78-9f95-6f2151d01454",
   "metadata": {},
   "source": [
    "## 5. Supervised learning setup\n",
    "\n",
    "After feature engineering, the problem must be formally defined as a supervised machine learning task.\n",
    "\n",
    "In this project, the objective is to predict the *next-day closing price* based on historical price behaviour and technical indicators.\n",
    "Although the model outputs a numeric price, the evaluation focuses on *trend prediction*, i.e., whether the model correctly predicts\n",
    "the direction of price movement (upward or downward).\n",
    "\n",
    "Key design decisions at this stage include:\n",
    "- Defining the prediction target using a one-day forecast horizon\n",
    "- Separating features from target variables\n",
    "- Performing a *chronological train–test split* to prevent look-ahead bias\n",
    "- Establishing evaluation metrics appropriate for financial time-series data\n",
    "\n",
    "This formulation ensures that all models are trained and tested under realistic market conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c00f6-68a4-44ba-a3b0-fc5bc976011f",
   "metadata": {},
   "source": [
    "### 5.1 Target Variable Creation\n",
    "\n",
    "In this section, the target variables are created for both stock and cryptocurrency datasets. The target represents the next-day closing price, enabling the models to learn one-step-ahead price prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063ec07-d2c9-43eb-890f-edb1ebcfab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 5.1 Target variable construction\n",
    "# ==================================\n",
    "\n",
    "# Create next-day prediction targets\n",
    "features_df[\"Target_AAPL\"] = features_df[\"Close_AAPL\"].shift(-1)\n",
    "features_df[\"Target_BTC\"] = features_df[\"Close_BTC\"].shift(-1)\n",
    "\n",
    "# Remove last row (no future target available)\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "print(\"Dataset shape after target creation:\", features_df.shape)\n",
    "features_df[[\"Close_AAPL\", \"Target_AAPL\", \"Close_BTC\", \"Target_BTC\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08074ae-5cea-44fa-9457-05115b46761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 5.1.5 Direction Target Creation (NEW)\n",
    "# ==================================\n",
    "\n",
    "# Binary classification: 1 = price goes up, 0 = price goes down\n",
    "features_df[\"Direction_AAPL\"] = (\n",
    "    features_df[\"Target_AAPL\"] > features_df[\"Close_AAPL\"]\n",
    ").astype(int)\n",
    "\n",
    "features_df[\"Direction_BTC\"] = (\n",
    "    features_df[\"Target_BTC\"] > features_df[\"Close_BTC\"]\n",
    ").astype(int)\n",
    "\n",
    "# Check class balance\n",
    "print(\"AAPL Direction Distribution:\")\n",
    "print(features_df[\"Direction_AAPL\"].value_counts())\n",
    "print(f\"Percentage going up: {features_df['Direction_AAPL'].mean():.2%}\")\n",
    "\n",
    "print(\"\\nBTC Direction Distribution:\")\n",
    "print(features_df[\"Direction_BTC\"].value_counts())\n",
    "print(f\"Percentage going up: {features_df['Direction_BTC'].mean():.2%}\")\n",
    "\n",
    "# Visualize direction distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "features_df[\"Direction_AAPL\"].value_counts().plot(\n",
    "    kind='bar', ax=axes[0], color=['red', 'green']\n",
    ")\n",
    "axes[0].set_title(\"AAPL Direction Distribution\")\n",
    "axes[0].set_xlabel(\"Direction (0=Down, 1=Up)\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].set_xticklabels(['Down', 'Up'], rotation=0)\n",
    "\n",
    "features_df[\"Direction_BTC\"].value_counts().plot(\n",
    "    kind='bar', ax=axes[1], color=['red', 'green']\n",
    ")\n",
    "axes[1].set_title(\"BTC Direction Distribution\")\n",
    "axes[1].set_xlabel(\"Direction (0=Down, 1=Up)\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].set_xticklabels(['Down', 'Up'], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"direction_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b814f0-1749-49b6-b054-b6c5ebe2117e",
   "metadata": {},
   "source": [
    "### 5.2 Feature and Target Separation\n",
    "\n",
    "This section separates the dataset into input features and target variables.The features are used as inputs to the machine learning models, while the target variables represent the values to be predicted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1ce8c-27c6-4c89-b7ca-8f2925107df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 5.2 Feature and target separation \n",
    "# ==================================\n",
    "\n",
    "# Define which columns to EXCLUDE from features\n",
    "EXCLUDE_COLUMNS = [\n",
    "    \"Target_AAPL\", \n",
    "    \"Target_BTC\",\n",
    "    \"Direction_AAPL\",   \n",
    "    \"Direction_BTC\",     \n",
    "    \"Close_AAPL\",     \n",
    "    \"Close_BTC\",       \n",
    "]\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    col for col in features_df.columns\n",
    "    if col not in EXCLUDE_COLUMNS\n",
    "]\n",
    "\n",
    "print(\"Excluded columns:\", EXCLUDE_COLUMNS)\n",
    "print(\"Number of features:\", len(FEATURE_COLUMNS))\n",
    "print(\"\\nFeatures used:\")\n",
    "for i, col in enumerate(FEATURE_COLUMNS, 1):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "X = features_df[FEATURE_COLUMNS]\n",
    "y_stock = features_df[\"Target_AAPL\"]\n",
    "y_crypto = features_df[\"Target_BTC\"]\n",
    "y_stock_direction = features_df[\"Direction_AAPL\"]\n",
    "y_crypto_direction = features_df[\"Direction_BTC\"]\n",
    "\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y_stock shape: {y_stock.shape}\")\n",
    "print(f\"y_crypto shape: {y_crypto.shape}\")\n",
    "print(\"Number of features:\", X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d1605-9a35-426c-b47d-c7676f016651",
   "metadata": {},
   "source": [
    "### 5.3 Train and Test Split\n",
    "\n",
    "The dataset is split into training and testing sets using a time-based approach.This ensures that future data is not used to predict past values and prevents data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cd1db-fd9a-462f-ac25-591a9b8e5394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 5.3 Time-aware train-test split \n",
    "# ==================================\n",
    "\n",
    "def time_series_split(X, y, y_direction, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits data chronologically into training and testing sets.\n",
    "    Now also splits direction targets.\n",
    "    \"\"\"\n",
    "    split_idx = int(len(X) * (1 - test_size))\n",
    "    X_train = X.iloc[:split_idx]\n",
    "    X_test = X.iloc[split_idx:]\n",
    "    y_train = y.iloc[:split_idx]\n",
    "    y_test = y.iloc[split_idx:]\n",
    "    y_dir_train = y_direction.iloc[:split_idx]\n",
    "    y_dir_test = y_direction.iloc[split_idx:]\n",
    "    return X_train, X_test, y_train, y_test, y_dir_train, y_dir_test\n",
    "\n",
    "# Stock split\n",
    "(X_train_stock, X_test_stock, \n",
    " y_train_stock, y_test_stock,\n",
    " y_train_stock_dir, y_test_stock_dir) = time_series_split(\n",
    "    X, y_stock, y_stock_direction, TEST_SIZE\n",
    ")\n",
    "\n",
    "# Crypto split\n",
    "(X_train_crypto, X_test_crypto, \n",
    " y_train_crypto, y_test_crypto,\n",
    " y_train_crypto_dir, y_test_crypto_dir) = time_series_split(\n",
    "    X, y_crypto, y_crypto_direction, TEST_SIZE\n",
    ")\n",
    "\n",
    "print(\"Stock train size:\", X_train_stock.shape)\n",
    "print(\"Stock test size:\", X_test_stock.shape)\n",
    "print(f\"Train direction split: {y_train_stock_dir.mean():.2%} up\")\n",
    "print(f\"Test direction split: {y_test_stock_dir.mean():.2%} up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd7f6c-234a-413f-ae97-3f6a3e6e8a1f",
   "metadata": {},
   "source": [
    "### 5.4 Training and Testing Date Validation\n",
    "\n",
    "This section verifies the date ranges of the training and testing datasets. It ensures that the chronological order of the data is preserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4748134-ca2e-4691-8b06-5e79c648fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 5.4 Evaluation metrics\n",
    "# ==================================\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes standard regression metrics.\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)     \n",
    "    rmse = np.sqrt(mse)                          \n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-9))) * 100\n",
    "    return mae, rmse, mape\n",
    "\n",
    "\n",
    "def directional_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes directional accuracy (trend prediction accuracy).\n",
    "    \"\"\"\n",
    "    true_dir = np.sign(y_true.diff().dropna())\n",
    "    pred_dir = np.sign(pd.Series(y_pred, index=y_true.index).diff().dropna())\n",
    "    return (true_dir == pred_dir).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef049c-4d99-4305-9b7a-e1a4f53708b5",
   "metadata": {},
   "source": [
    "### 5.5 Final Dataset Preparation for Modeling\n",
    "\n",
    "This section confirms that the dataset is fully prepared for model training. The features, targets and splits are validated and ready to be used in\n",
    "machine learning and deep learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3251ea-d6ab-408e-aede-1ec37afc9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 5.5 Baseline model training template\n",
    "# ==================================\n",
    "\n",
    "def train_random_forest(X_train, y_train, n_estimators=200):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest regressor.\n",
    "    \"\"\"\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    return rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c273a-9541-4f59-92b0-1de06583ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dates for training and testing\n",
    "print(\"First date in training:\", X_train_stock.index.min())\n",
    "print(\"Last date in training:\", X_train_stock.index.max())\n",
    "print(\"First date in testing:\", X_test_stock.index.min())\n",
    "print(\"Last date in testing:\", X_test_stock.index.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17511949-f6a4-45e4-89b6-fb219fee0e9b",
   "metadata": {},
   "source": [
    "## 6 Classical Regression and Baseline Models\n",
    "\n",
    "Classical regression approaches are implemented as baseline methods. These models establish a\n",
    "lower-bound benchmark for predictive performance and help assess the degree of non-linearity and temporal complexity present in the data.\n",
    "\n",
    "The following regression models are considered:\n",
    "- Linear Regression\n",
    "- Ridge Regression (L2-regularised linear regression)\n",
    "- Support Vector Regression (SVR) with RBF kernel\n",
    "\n",
    "Baseline models provide a point of comparison and help determine whether more complex architectures offer meaningful performance improvements.\n",
    "\n",
    "The following supervised learning models are implemented:\n",
    "- Random Forest Regressor\n",
    "- XGBoost Regressor \n",
    "\n",
    "Both models are trained separately on stock and cryptocurrency datasets. Performance is evaluated using both regression metrics and directional accuracy, reflecting the dual objectives of price estimation and trend prediction.\n",
    "\n",
    "All models are trained using the same chronological train-test split to ensure fair comparison with subsequent models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3452b1-92af-4bf6-a079-cb69fc498ed3",
   "metadata": {},
   "source": [
    "### 6.1 Linear Regression – Stock Prediction (AAPL)\n",
    "\n",
    "Linear Regression is implemented as a simple baseline model that assumes a linear relationship between input features and the target variable. Although\n",
    "financial markets are inherently non-linear, this model provides a useful reference point for evaluating more complex approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323c53e-d4be-440a-bf73-8725b265eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Linear Regression\n",
    "lr_stock = LinearRegression()\n",
    "lr_stock.fit(X_train_stock, y_train_stock)\n",
    "\n",
    "y_pred_lr_stock = lr_stock.predict(X_test_stock)\n",
    "\n",
    "mae_lr_stock, rmse_lr_stock, mape_lr_stock = regression_metrics(\n",
    "    y_test_stock, y_pred_lr_stock\n",
    ")\n",
    "dir_acc_lr_stock = directional_accuracy(y_test_stock, y_pred_lr_stock)\n",
    "\n",
    "print(\"Linear Regression – AAPL\")\n",
    "print(f\"MAE  : {mae_lr_stock:.4f}\")\n",
    "print(f\"RMSE : {rmse_lr_stock:.4f}\")\n",
    "print(f\"MAPE : {mape_lr_stock:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_lr_stock:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb870fe-bead-47a6-b10f-d4d7d3822764",
   "metadata": {},
   "source": [
    "### 6.2 Ridge Regression – Stock Prediction (AAPL)\n",
    "\n",
    "Ridge Regression extends linear regression by introducing L2 regularisation,which helps mitigate multicollinearity among technical indicators and reduces model variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c35bd-f149-4e8b-af8f-e9c9bad5a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "ridge_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha=1.0, random_state=SEED))\n",
    "])\n",
    "\n",
    "ridge_pipe.fit(X_train_stock, y_train_stock)\n",
    "y_pred_ridge_stock = ridge_pipe.predict(X_test_stock)\n",
    "\n",
    "mae_ridge_stock, rmse_ridge_stock, mape_ridge_stock = regression_metrics(y_test_stock, y_pred_ridge_stock)\n",
    "dir_acc_ridge_stock = directional_accuracy(y_test_stock, y_pred_ridge_stock)\n",
    "\n",
    "print(\"Ridge Regression – AAPL\")\n",
    "print(f\"MAE  : {mae_ridge_stock:.4f}\")\n",
    "print(f\"RMSE : {rmse_ridge_stock:.4f}\")\n",
    "print(f\"MAPE : {mape_ridge_stock:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_ridge_stock:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df721da-b7f9-4a33-b516-ca7508b074dd",
   "metadata": {},
   "source": [
    "### 6.3 Support Vector Regression – Stock Prediction (AAPL)\n",
    "\n",
    "Support Vector Regression (SVR) with an RBF kernel is employed to model non-linear relationships between technical indicators and stock prices.\n",
    "SVR serves as a strong classical machine learning baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae22c8-3dac-4178-8ef2-3206cf8d7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVR requires scaling\n",
    "svr_x_scaler = StandardScaler()\n",
    "svr_y_scaler = StandardScaler()\n",
    "\n",
    "X_train_svr = svr_x_scaler.fit_transform(X_train_stock)\n",
    "X_test_svr = svr_x_scaler.transform(X_test_stock)\n",
    "\n",
    "y_train_svr = svr_y_scaler.fit_transform(\n",
    "    y_train_stock.values.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "svr_stock = SVR(kernel=\"rbf\", C=100, gamma=\"scale\", epsilon=0.1)\n",
    "svr_stock.fit(X_train_svr, y_train_svr)\n",
    "\n",
    "y_pred_svr_scaled = svr_stock.predict(X_test_svr)\n",
    "y_pred_svr_stock = svr_y_scaler.inverse_transform(\n",
    "    y_pred_svr_scaled.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "mae_svr_stock, rmse_svr_stock, mape_svr_stock = regression_metrics(\n",
    "    y_test_stock, y_pred_svr_stock\n",
    ")\n",
    "dir_acc_svr_stock = directional_accuracy(y_test_stock, y_pred_svr_stock)\n",
    "\n",
    "print(\"SVR (RBF) – AAPL\")\n",
    "print(f\"MAE  : {mae_svr_stock:.4f}\")\n",
    "print(f\"RMSE : {rmse_svr_stock:.4f}\")\n",
    "print(f\"MAPE : {mape_svr_stock:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_svr_stock:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2bf3e-edee-4c59-9e09-165699e80f84",
   "metadata": {},
   "source": [
    "### 6.4 Random Forest Baseline – Stock Prediction\n",
    "\n",
    "A Random Forest regression model is trained as a baseline for predicting AAPL prices. This model captures nonlinear feature relationships without considering temporal dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d202f1-3861-4a64-a4e3-62c5e5acf8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Random Forest – Stock (AAPL)\n",
    "# ==================================\n",
    "\n",
    "rf_stock = train_random_forest(X_train_stock, y_train_stock)\n",
    "\n",
    "y_pred_rf_stock = rf_stock.predict(X_test_stock)\n",
    "\n",
    "mae_s, rmse_s, mape_s = regression_metrics(y_test_stock, y_pred_rf_stock)\n",
    "dir_acc_s = directional_accuracy(y_test_stock, y_pred_rf_stock)\n",
    "\n",
    "print(\"Random Forest – AAPL\")\n",
    "print(f\"MAE  : {mae_s:.4f}\")\n",
    "print(f\"RMSE : {rmse_s:.4f}\")\n",
    "print(f\"MAPE : {mape_s:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_s:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15790d00-d5d4-47a4-882e-735df1be9d91",
   "metadata": {},
   "source": [
    "### 6.5 Random Forest Baseline – Cryptocurrency Prediction\n",
    "\n",
    "The Random Forest model is applied to BTC-USD data to establish a baseline performance for cryptocurrency price prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3064c-5f7c-4e26-a97b-3744ed2e0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Random Forest – Crypto (BTC)\n",
    "# ==================================\n",
    "\n",
    "rf_crypto = train_random_forest(X_train_crypto, y_train_crypto)\n",
    "\n",
    "y_pred_rf_crypto = rf_crypto.predict(X_test_crypto)\n",
    "\n",
    "mae_c, rmse_c, mape_c = regression_metrics(y_test_crypto, y_pred_rf_crypto)\n",
    "dir_acc_c = directional_accuracy(y_test_crypto, y_pred_rf_crypto)\n",
    "\n",
    "print(\"Random Forest – BTC-USD\")\n",
    "print(f\"MAE  : {mae_c:.4f}\")\n",
    "print(f\"RMSE : {rmse_c:.4f}\")\n",
    "print(f\"MAPE : {mape_c:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_c:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49388b4d-ba54-4927-9db2-6b27067e9c05",
   "metadata": {},
   "source": [
    "### 6.6 XGBoost Model – Stock Prediction\n",
    "\n",
    "An XGBoost regression model is trained for AAPL to compare gradient-boosted trees against Random Forest and deep learning approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8ccc6-04cb-4954-b09b-ccf001217b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# XGBoost baseline \n",
    "# ==================================\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    xgb_stock = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    xgb_stock.fit(X_train_stock, y_train_stock)\n",
    "    y_pred_xgb_stock = xgb_stock.predict(X_test_stock)\n",
    "\n",
    "    mae_x, rmse_x, mape_x = regression_metrics(y_test_stock, y_pred_xgb_stock)\n",
    "    dir_acc_x = directional_accuracy(y_test_stock, y_pred_xgb_stock)\n",
    "\n",
    "    print(\"XGBoost – AAPL\")\n",
    "    print(f\"MAE  : {mae_x:.4f}\")\n",
    "    print(f\"RMSE : {rmse_x:.4f}\")\n",
    "    print(f\"MAPE : {mape_x:.2f}%\")\n",
    "    print(f\"Directional Accuracy: {dir_acc_x:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd0a44-e742-458d-b79a-a0ddc379a960",
   "metadata": {},
   "source": [
    "### 6.6 Feature Importance Analysis\n",
    "\n",
    "Feature importance scores from tree-based models are visualized to identify the most influential predictors contributing to price prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5330a-003c-4689-bdee-dbe820e915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "#  Feature importance analysis\n",
    "# ==================================\n",
    "\n",
    "importances = pd.Series(\n",
    "    rf_stock.feature_importances_,\n",
    "    index=X_train_stock.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "importances.head(5).plot(kind=\"barh\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 5 Feature Importances (Random Forest – AAPL)\")\n",
    "plt.tight_layout()\n",
    "savefig(\"rf_feature_importance.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67dc91c-d530-4e7f-af94-752ee5aa7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 6.8 Hyperparameter Optimization (NEW)\n",
    "# ==================================\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HYPERPARAMETER OPTIMIZATION - RANDOM FOREST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define parameter distribution\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': [10, 20, 30, 40, None],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Create base model\n",
    "rf_base = RandomForestRegressor(random_state=SEED, n_jobs=-1)\n",
    "\n",
    "# Randomized search\n",
    "print(\"\\nSearching for optimal hyperparameters...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,  # Number of parameter settings to try\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the random search\n",
    "random_search.fit(X_train_stock, y_train_stock)\n",
    "\n",
    "print(\"\\n✓ Optimization complete!\")\n",
    "print(\"\\nBest parameters found:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest cross-validation MAE: {-random_search.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "rf_optimized = random_search.best_estimator_\n",
    "y_pred_rf_optimized = rf_optimized.predict(X_test_stock)\n",
    "\n",
    "# Evaluate\n",
    "mae_rf_opt, rmse_rf_opt, mape_rf_opt = regression_metrics(\n",
    "    y_test_stock, y_pred_rf_optimized\n",
    ")\n",
    "dir_acc_rf_opt = directional_accuracy(y_test_stock, y_pred_rf_optimized)\n",
    "\n",
    "print(\"\\nOptimized Random Forest Performance:\")\n",
    "print(f\"  MAE:                   {mae_rf_opt:.4f}\")\n",
    "print(f\"  RMSE:                  {rmse_rf_opt:.4f}\")\n",
    "print(f\"  MAPE:                  {mape_rf_opt:.2f}%\")\n",
    "print(f\"  Directional Accuracy:  {dir_acc_rf_opt:.2%}\")\n",
    "\n",
    "print(\"\\nComparison with default parameters:\")\n",
    "print(f\"  MAE improvement:       {(1 - mae_rf_opt/mae_rf_stock)*100:.2f}%\")\n",
    "print(f\"  RMSE improvement:      {(1 - rmse_rf_opt/rmse_rf_stock)*100:.2f}%\")\n",
    "print(f\"  Dir_Acc improvement:   {(dir_acc_rf_opt - dir_acc_rf_stock)*100:.2f} percentage points\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2778260-28e3-4a70-96c7-0dd5c4b43b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hyperparameter search results\n",
    "cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "cv_results['mean_test_mae'] = -cv_results['mean_test_score']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Number of estimators vs MAE\n",
    "axes[0, 0].scatter(\n",
    "    cv_results['param_n_estimators'],\n",
    "    cv_results['mean_test_mae'],\n",
    "    alpha=0.6,\n",
    "    s=100\n",
    ")\n",
    "axes[0, 0].set_xlabel('Number of Estimators')\n",
    "axes[0, 0].set_ylabel('Cross-Validation MAE')\n",
    "axes[0, 0].set_title('n_estimators vs Performance')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Max depth vs MAE\n",
    "max_depth_values = [x if x is not None else 50 for x in cv_results['param_max_depth']]\n",
    "axes[0, 1].scatter(\n",
    "    max_depth_values,\n",
    "    cv_results['mean_test_mae'],\n",
    "    alpha=0.6,\n",
    "    s=100\n",
    ")\n",
    "axes[0, 1].set_xlabel('Max Depth (None → 50)')\n",
    "axes[0, 1].set_ylabel('Cross-Validation MAE')\n",
    "axes[0, 1].set_title('max_depth vs Performance')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Min samples split vs MAE\n",
    "axes[1, 0].scatter(\n",
    "cv_results['param_min_samples_split'],\n",
    "cv_results['mean_test_mae'],\n",
    "alpha=0.6,\n",
    "s=100\n",
    ")\n",
    "axes[1, 0].set_xlabel('Min Samples Split')\n",
    "axes[1, 0].set_ylabel('Cross-Validation MAE')\n",
    "axes[1, 0].set_title('min_samples_split vs Performance')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "# Plot 4: Performance over iterations\n",
    "axes[1, 1].plot(\n",
    "range(len(cv_results)),\n",
    "cv_results['mean_test_mae'],\n",
    "marker='o',\n",
    "linestyle='-',\n",
    "alpha=0.7\n",
    ")\n",
    "axes[1, 1].axhline(\n",
    "y=cv_results['mean_test_mae'].min(),\n",
    "color='red',\n",
    "linestyle='--',\n",
    "label=f'Best MAE: {cv_results[\"mean_test_mae\"].min():.4f}'\n",
    ")\n",
    "axes[1, 1].set_xlabel('Iteration')\n",
    "axes[1, 1].set_ylabel('Cross-Validation MAE')\n",
    "axes[1, 1].set_title('Optimization Progress')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "savefig(\"hyperparameter_optimization.png\")\n",
    "plt.show()\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7bf7b-be38-4fe6-a2ca-733a3e4b0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Random Forest Classifier for Direction \n",
    "# ==================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RANDOM FOREST CLASSIFIER - AAPL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train classifier\n",
    "rf_classifier_stock = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',  # Handle any class imbalance\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_classifier_stock.fit(X_train_stock, y_train_stock_dir)\n",
    "y_pred_dir_rf_stock = rf_classifier_stock.predict(X_test_stock)\n",
    "y_pred_proba_rf_stock = rf_classifier_stock.predict_proba(X_test_stock)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "acc_rf_stock = accuracy_score(y_test_stock_dir, y_pred_dir_rf_stock)\n",
    "prec_rf_stock = precision_score(y_test_stock_dir, y_pred_dir_rf_stock)\n",
    "rec_rf_stock = recall_score(y_test_stock_dir, y_pred_dir_rf_stock)\n",
    "f1_rf_stock = f1_score(y_test_stock_dir, y_pred_dir_rf_stock)\n",
    "auc_rf_stock = roc_auc_score(y_test_stock_dir, y_pred_proba_rf_stock)\n",
    "\n",
    "print(f\"Accuracy:  {acc_rf_stock:.2%}\")\n",
    "print(f\"Precision: {prec_rf_stock:.2%}\")\n",
    "print(f\"Recall:    {rec_rf_stock:.2%}\")\n",
    "print(f\"F1-Score:  {f1_rf_stock:.2%}\")\n",
    "print(f\"ROC AUC:   {auc_rf_stock:.2%}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test_stock_dir, \n",
    "    y_pred_dir_rf_stock,\n",
    "    target_names=['Down', 'Up']\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f655d29-deb5-40d5-9a3e-8b7799299913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_rf_stock = confusion_matrix(y_test_stock_dir, y_pred_dir_rf_stock)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Confusion Matrix\n",
    "sns.heatmap(\n",
    "    cm_rf_stock, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    ax=axes[0],\n",
    "    xticklabels=['Predicted Down', 'Predicted Up'],\n",
    "    yticklabels=['Actual Down', 'Actual Up']\n",
    ")\n",
    "axes[0].set_title(\"Confusion Matrix - RF Classifier (AAPL)\")\n",
    "axes[0].set_ylabel(\"True Label\")\n",
    "axes[0].set_xlabel(\"Predicted Label\")\n",
    "\n",
    "# Plot 2: ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_stock_dir, y_pred_proba_rf_stock)\n",
    "axes[1].plot(fpr, tpr, label=f'RF (AUC = {auc_rf_stock:.3f})', linewidth=2)\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve - RF Classifier (AAPL)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"rf_classifier_aapl.png\")\n",
    "plt.show()\n",
    "\n",
    "# Directional accuracy from regression predictions (Random Forest regression)\n",
    "dir_acc_rf_stock = np.mean(\n",
    "    np.sign(y_test_stock.values[1:] - y_test_stock.values[:-1]) ==\n",
    "    np.sign(y_pred_rf_stock[1:] - y_pred_rf_stock[:-1])\n",
    ")\n",
    "\n",
    "# Compare with regression directional accuracy\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARISON: Regression vs Classification\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Regression Model (Directional Accuracy): {dir_acc_rf_stock:.2%}\")\n",
    "print(f\"Classification Model (Accuracy):         {acc_rf_stock:.2%}\")\n",
    "print(f\"Improvement: {(acc_rf_stock - dir_acc_rf_stock):.2%}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d82a92-039b-4112-979a-aed631d8ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 6.10 Random Forest Classifier - BTC \n",
    "# ==================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RANDOM FOREST CLASSIFIER - BTC-USD\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "rf_classifier_crypto = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_classifier_crypto.fit(X_train_crypto, y_train_crypto_dir)\n",
    "y_pred_dir_rf_crypto = rf_classifier_crypto.predict(X_test_crypto)\n",
    "y_pred_proba_rf_crypto = rf_classifier_crypto.predict_proba(X_test_crypto)[:, 1]\n",
    "\n",
    "acc_rf_crypto = accuracy_score(y_test_crypto_dir, y_pred_dir_rf_crypto)\n",
    "prec_rf_crypto = precision_score(y_test_crypto_dir, y_pred_dir_rf_crypto)\n",
    "rec_rf_crypto = recall_score(y_test_crypto_dir, y_pred_dir_rf_crypto)\n",
    "f1_rf_crypto = f1_score(y_test_crypto_dir, y_pred_dir_rf_crypto)\n",
    "auc_rf_crypto = roc_auc_score(y_test_crypto_dir, y_pred_proba_rf_crypto)\n",
    "\n",
    "print(f\"Accuracy:  {acc_rf_crypto:.2%}\")\n",
    "print(f\"Precision: {prec_rf_crypto:.2%}\")\n",
    "print(f\"Recall:    {rec_rf_crypto:.2%}\")\n",
    "print(f\"F1-Score:  {f1_rf_crypto:.2%}\")\n",
    "print(f\"ROC AUC:   {auc_rf_crypto:.2%}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test_crypto_dir, \n",
    "    y_pred_dir_rf_crypto,\n",
    "    target_names=['Down', 'Up']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fae90d-8fe4-41dd-85ed-17afc80a7188",
   "metadata": {},
   "source": [
    "## 7. LSTM model development\n",
    "\n",
    "Traditional machine learning models treat observations as independent samples and therefore struggle to capture temporal dependencies present in financial time-series data.\n",
    "\n",
    "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network designed to learn sequential patterns over time.They are particularly well-suited for financial forecasting tasks where historical price movements influence future behaviour.\n",
    "\n",
    "In this section, LSTM models are developed to predict next-day prices for:\n",
    "- Apple Inc. (AAPL)\n",
    "- Bitcoin (BTC-USD)\n",
    "\n",
    "Key steps include:\n",
    "- Feature scaling\n",
    "- Sequence construction using a fixed lookback window\n",
    "- LSTM model architecture design\n",
    "- Model training with validation\n",
    "- Performance evaluation on unseen test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c815e6e3-4c5b-4e02-8297-f610fa178974",
   "metadata": {},
   "source": [
    "### 7.1 Data Scaling for LSTM\n",
    "\n",
    "This section applies feature scaling to ensure that input variables are within a similar numerical range, which is critical for stable LSTM training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548855a-f602-4c43-a75c-d0d24d710be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 7.1 Feature scaling for LSTM\n",
    "# ==================================\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = x_scaler.fit_transform(X_train_stock)\n",
    "X_test_scaled  = x_scaler.transform(X_test_stock)\n",
    "\n",
    "# y must be 2D for scaler\n",
    "y_train_scaled = y_scaler.fit_transform(y_train_stock.values.reshape(-1, 1))\n",
    "y_test_scaled  = y_scaler.transform(y_test_stock.values.reshape(-1, 1))\n",
    "\n",
    "print(\"X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"y_train_scaled:\", y_train_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca502ad6-e166-43c8-aeb4-84fee79c0427",
   "metadata": {},
   "source": [
    "### 7.2 LSTM Sequence Preparation\n",
    "\n",
    "Input data is converted into rolling time-window sequences to enable the LSTM model to learn temporal dependencies in the financial time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0e6e2-0fe5-4d16-86dd-2a19df45ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 7.2 Create LSTM sequences\n",
    "# ==================================\n",
    "\n",
    "def create_sequences_xy(X, y, lookback):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(lookback, len(X)):\n",
    "        X_seq.append(X[i - lookback:i])\n",
    "        y_seq.append(y[i])  # scaled target\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences_xy(X_train_scaled, y_train_scaled, LOOKBACK_WINDOW)\n",
    "X_test_seq, y_test_seq   = create_sequences_xy(X_test_scaled,  y_test_scaled,  LOOKBACK_WINDOW)\n",
    "\n",
    "print(\"Train seq:\", X_train_seq.shape, y_train_seq.shape)\n",
    "print(\"Test seq :\", X_test_seq.shape, y_test_seq.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f5ff3-a25b-4c67-9b52-ef0ea1636dec",
   "metadata": {},
   "source": [
    "### 7.3 LSTM Model Architecture\n",
    "\n",
    "An LSTM neural network is defined to model sequential dependencies in stock price data. The architecture includes dropout regularisation to mitigate overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1292f2-c4f8-4f11-b4f5-8c0e8472b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 7.3 LSTM model architecture\n",
    "# ==================================\n",
    "\n",
    "def build_lstm(input_shape):\n",
    "    \"\"\"\n",
    "    Builds a LSTM regression model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=False, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "lstm_model = build_lstm(\n",
    "    input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])\n",
    ")\n",
    "\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1d87fd-cba6-4185-bf08-97154db02ab6",
   "metadata": {},
   "source": [
    "### 7.4 LSTM Model Training\n",
    "\n",
    "The LSTM model is trained using the prepared sequences. Training and validation losses are monitored to assess convergence and generalisation performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4452e3c-d8e9-4657-a84b-ff027c358508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 7.4 Train LSTM model\n",
    "# ==================================\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-5\n",
    ")\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    X_train_seq,\n",
    "    y_train_seq,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6e5df-47e5-4773-9e7b-36988331662d",
   "metadata": {},
   "source": [
    "### 7.5 LSTM Model Evaluation\n",
    "\n",
    "The trained LSTM model is evaluated on the test dataset using multiple error metrics and directional accuracy to assess predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64aa85-82fa-4aa3-b1f9-1a84b646bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 7.5 Evaluate LSTM performance\n",
    "# ==================================\n",
    "\n",
    "y_pred_scaled = lstm_model.predict(X_test_seq).flatten()\n",
    "\n",
    "# Inverse transform back to price scale\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_true = y_scaler.inverse_transform(y_test_seq.reshape(-1, 1)).flatten()\n",
    "\n",
    "mae_l, rmse_l, mape_l = regression_metrics(pd.Series(y_true), y_pred)\n",
    "dir_acc_l = directional_accuracy(pd.Series(y_true), y_pred)\n",
    "\n",
    "print(\"LSTM – AAPL (fixed scaling)\")\n",
    "print(f\"MAE  : {mae_l:.4f}\")\n",
    "print(f\"RMSE : {rmse_l:.4f}\")\n",
    "print(f\"MAPE : {mape_l:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_l:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95149ac8-1e52-4ee7-919d-e54da8b46340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# LSTM Classifier for Direction \n",
    "# ==================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LSTM CLASSIFIER - AAPL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Need to create sequences for direction labels\n",
    "def create_sequences_classification(X, y_direction, lookback):\n",
    "    \"\"\"\n",
    "    Creates sequences for classification task.\n",
    "    y_direction should be binary labels (0 or 1).\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(lookback, len(X)):\n",
    "        X_seq.append(X[i - lookback:i])\n",
    "        y_seq.append(y_direction[i])  # Binary label\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Convert direction labels to numpy arrays\n",
    "y_train_dir_arr = y_train_stock_dir.values\n",
    "y_test_dir_arr = y_test_stock_dir.values\n",
    "\n",
    "# Create sequences (reuse scaled data from Section 7.1)\n",
    "X_train_seq_clf, y_train_seq_clf = create_sequences_classification(\n",
    "    X_train_scaled, y_train_dir_arr, LOOKBACK_WINDOW\n",
    ")\n",
    "X_test_seq_clf, y_test_seq_clf = create_sequences_classification(\n",
    "    X_test_scaled, y_test_dir_arr, LOOKBACK_WINDOW\n",
    ")\n",
    "\n",
    "print(f\"Train sequences: {X_train_seq_clf.shape}, {y_train_seq_clf.shape}\")\n",
    "print(f\"Test sequences:  {X_test_seq_clf.shape}, {y_test_seq_clf.shape}\")\n",
    "\n",
    "# Build LSTM Classifier\n",
    "def build_lstm_classifier(input_shape):\n",
    "    \"\"\"\n",
    "    Builds LSTM binary classifier.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=False, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')  # ← Sigmoid for binary classification\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',  # ← Binary crossentropy for classification\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "lstm_classifier = build_lstm_classifier(\n",
    "    input_shape=(X_train_seq_clf.shape[1], X_train_seq_clf.shape[2])\n",
    ")\n",
    "lstm_classifier.summary()\n",
    "\n",
    "# Train LSTM Classifier\n",
    "history_clf = lstm_classifier.fit(\n",
    "    X_train_seq_clf,\n",
    "    y_train_seq_clf,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31171d3f-e369-4a9e-87c6-d50bd3051df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred_proba_lstm = lstm_classifier.predict(X_test_seq_clf).flatten()\n",
    "y_pred_dir_lstm = (y_pred_proba_lstm > 0.5).astype(int)\n",
    "\n",
    "acc_lstm_clf = accuracy_score(y_test_seq_clf, y_pred_dir_lstm)\n",
    "prec_lstm_clf = precision_score(y_test_seq_clf, y_pred_dir_lstm)\n",
    "rec_lstm_clf = recall_score(y_test_seq_clf, y_pred_dir_lstm)\n",
    "f1_lstm_clf = f1_score(y_test_seq_clf, y_pred_dir_lstm)\n",
    "auc_lstm_clf = roc_auc_score(y_test_seq_clf, y_pred_proba_lstm)\n",
    "\n",
    "print(\"\\nLSTM Classifier Results:\")\n",
    "print(f\"Accuracy:  {acc_lstm_clf:.2%}\")\n",
    "print(f\"Precision: {prec_lstm_clf:.2%}\")\n",
    "print(f\"Recall:    {rec_lstm_clf:.2%}\")\n",
    "print(f\"F1-Score:  {f1_lstm_clf:.2%}\")\n",
    "print(f\"ROC AUC:   {auc_lstm_clf:.2%}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test_seq_clf, \n",
    "    y_pred_dir_lstm,\n",
    "    target_names=['Down', 'Up']\n",
    "))\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history_clf.history['loss'], label='Training Loss')\n",
    "axes[0].plot(history_clf.history['val_loss'], label='Validation Loss')\n",
    "axes[0].set_title('LSTM Classifier Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Binary Crossentropy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history_clf.history['accuracy'], label='Training Accuracy')\n",
    "axes[1].plot(history_clf.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[1].set_title('LSTM Classifier Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"lstm_classifier_training.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d92019-4c72-44d1-bbdd-15d11a721ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias LSTM regression outputs for consistency in later sections\n",
    "y_pred_lstm = y_pred\n",
    "y_true_lstm = y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da2be12-2992-405b-86a4-5a4d9c2d84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "#  LSTM training loss plot\n",
    "# ==================================\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"LSTM Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "savefig(\"lstm_training_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a2b4c-ca4d-4a73-828f-d3351694b3b1",
   "metadata": {},
   "source": [
    "## 8. Hybrid RF → LSTM model\n",
    "\n",
    "A hybrid modelling strategy is used to combine the strengths of tree-based feature selection and sequence-based deep learning.\n",
    "\n",
    "- Random Forest models are effective at identifying informative features using feature importance measures.\n",
    "- LSTMs are effective at learning sequential patterns over time, but they may perform poorly if trained on noisy or redundant features.\n",
    "\n",
    "This hybrid approach proceeds in two stages:\n",
    "\n",
    "1. Train a Random Forest model on the training set.\n",
    "2. Select the top N features based on feature importances.\n",
    "3. Train an LSTM model using only these selected features.\n",
    "\n",
    "This design improves interpretability and can enhance performance by reducing input dimensionality and limiting noise in the LSTM learning process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f5afa-44ad-4aa6-9b3b-0c23c944ecd0",
   "metadata": {},
   "source": [
    "### 8.1 Feature Selection Using Random Forest\n",
    "\n",
    "Random Forest feature importance is used to select a reduced subset of influential features. This step aims to improve LSTM efficiency and reduce noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf39230-7fd4-4fca-9865-75c71509fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 8.1 Select top features using RF importance (AAPL)\n",
    "# ==================================\n",
    "\n",
    "def get_top_features_from_rf(rf_model, feature_names, top_n=5):\n",
    "    \"\"\"\n",
    "    Returns top_n feature names based on Random Forest feature importances.\n",
    "    \"\"\"\n",
    "    imp = pd.Series(rf_model.feature_importances_, index=feature_names)\n",
    "    top_features = imp.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    return top_features, imp.sort_values(ascending=False)\n",
    "\n",
    "TOP_N = 5\n",
    "\n",
    "top_features_aapl, full_importance_aapl = get_top_features_from_rf(\n",
    "    rf_stock, X_train_stock.columns, top_n=TOP_N\n",
    ")\n",
    "\n",
    "print(\"Top features (AAPL):\")\n",
    "for i, f in enumerate(top_features_aapl, start=1):\n",
    "    print(f\"{i}. {f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7046ea95-f6a0-43fe-8dae-57c40114cc9c",
   "metadata": {},
   "source": [
    "### 8.2 Reduced Feature Dataset Preparation\n",
    "\n",
    "The dataset is reconstructed using only the selected top features, preparing it for hybrid model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc31ba-3619-4dbb-9803-298ea2f1f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 8.2 Reduce dataset to top features + scale X and y\n",
    "# ==================================\n",
    "\n",
    "# Use only selected top features\n",
    "X_train_top = X_train_stock[top_features_aapl]\n",
    "X_test_top  = X_test_stock[top_features_aapl]\n",
    "\n",
    "# Scale X and y (train only fit → test transform)\n",
    "x_scaler_h = MinMaxScaler()\n",
    "y_scaler_h = MinMaxScaler()\n",
    "\n",
    "X_train_top_scaled = x_scaler_h.fit_transform(X_train_top)\n",
    "X_test_top_scaled  = x_scaler_h.transform(X_test_top)\n",
    "\n",
    "y_train_h_scaled = y_scaler_h.fit_transform(y_train_stock.values.reshape(-1, 1))\n",
    "y_test_h_scaled  = y_scaler_h.transform(y_test_stock.values.reshape(-1, 1))\n",
    "\n",
    "print(\"Reduced X_train shape:\", X_train_top_scaled.shape)\n",
    "print(\"Reduced X_test shape:\", X_test_top_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be67784-5fd1-48de-91d9-682cc7266cbb",
   "metadata": {},
   "source": [
    "### 8.3 Hybrid Model Sequence Preparation\n",
    "\n",
    "Time-series sequences are generated from the reduced feature set for training the hybrid RF→LSTM model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f3e7b-d212-4398-9f88-8457e600f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 8.3 Create sequences for hybrid LSTM\n",
    "# ==================================\n",
    "\n",
    "X_train_h_seq, y_train_h_seq = create_sequences_xy(\n",
    "    X_train_top_scaled, y_train_h_scaled, LOOKBACK_WINDOW\n",
    ")\n",
    "\n",
    "X_test_h_seq, y_test_h_seq = create_sequences_xy(\n",
    "    X_test_top_scaled, y_test_h_scaled, LOOKBACK_WINDOW\n",
    ")\n",
    "\n",
    "print(\"Hybrid train sequences:\", X_train_h_seq.shape, y_train_h_seq.shape)\n",
    "print(\"Hybrid test sequences :\", X_test_h_seq.shape, y_test_h_seq.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c526d5f-a8ab-42e5-869f-f54167f4ad23",
   "metadata": {},
   "source": [
    "### 8.4 Hybrid RF→LSTM Model Training\n",
    "\n",
    "The hybrid model is trained using the selected features and LSTM architecture.Training behaviour is monitored through loss curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c63eb97-65e7-489b-af14-52222706b023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 8.4 Build + train hybrid LSTM model\n",
    "# ==================================\n",
    "\n",
    "hybrid_lstm = build_lstm(\n",
    "    input_shape=(X_train_h_seq.shape[1], X_train_h_seq.shape[2])\n",
    ")\n",
    "\n",
    "hybrid_lstm.summary()\n",
    "\n",
    "history_hybrid = hybrid_lstm.fit(\n",
    "    X_train_h_seq,\n",
    "    y_train_h_seq,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b5bc0e-b71f-42de-8c17-21ec9cae687c",
   "metadata": {},
   "source": [
    "### 8.5 Hybrid Model Evaluation – Stock\n",
    "\n",
    "The hybrid RF→LSTM model is evaluated on AAPL test data and compared against baseline models to quantify performance improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6611bc8-d099-4697-b206-71415cafd8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 8.5 Evaluate hybrid RF → LSTM model\n",
    "# ==================================\n",
    "\n",
    "y_pred_h_scaled = hybrid_lstm.predict(X_test_h_seq).flatten()\n",
    "\n",
    "# Inverse scale predictions back to real prices\n",
    "y_pred_h = y_scaler_h.inverse_transform(y_pred_h_scaled.reshape(-1, 1)).flatten()\n",
    "y_true_h = y_scaler_h.inverse_transform(y_test_h_seq.reshape(-1, 1)).flatten()\n",
    "\n",
    "mae_h, rmse_h, mape_h = regression_metrics(pd.Series(y_true_h), y_pred_h)\n",
    "dir_acc_h = directional_accuracy(pd.Series(y_true_h), y_pred_h)\n",
    "\n",
    "print(\"Hybrid RF → LSTM – AAPL\")\n",
    "print(f\"MAE  : {mae_h:.4f}\")\n",
    "print(f\"RMSE : {rmse_h:.4f}\")\n",
    "print(f\"MAPE : {mape_h:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_h:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff42ea7-9f9d-4cde-8d0d-b470369c3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 8.6 Hybrid training loss curve\n",
    "# ==================================\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history_hybrid.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history_hybrid.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Hybrid RF→LSTM Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "savefig(\"hybrid_lstm_loss_aapl.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd4adbf-d507-4173-b820-5600ba55dda7",
   "metadata": {},
   "source": [
    "## 9. Model evaluation and visual diagnostics\n",
    "\n",
    "Quantitative metrics alone are insufficient to fully assess forecasting models.\n",
    "Therefore, visual diagnostic tools are employed to evaluate prediction quality, error behaviour and model stability.\n",
    "\n",
    "This section presents:\n",
    "- Actual vs predicted price plots\n",
    "- Residual diagnostics\n",
    "- Error distribution analysis\n",
    "- Comparative performance summary across models\n",
    "\n",
    "These visualisations support interpretability and provide empirical evidence for the effectiveness of the proposed hybrid model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4cf33-a269-4106-b5a7-cccb8562a3e5",
   "metadata": {},
   "source": [
    "### 9.1 Actual vs Predicted Price Comparison\n",
    "\n",
    "This section visualizes the actual and predicted stock prices over time to assess how well the hybrid model captures market dynamics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32133255-46cb-465b-a6a9-deb32e5d6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 9.1 Actual vs Predicted (Hybrid – AAPL)\n",
    "# ==================================\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_true_h, label=\"Actual Price\", linewidth=2)\n",
    "plt.plot(y_pred_h, label=\"Predicted Price\", linestyle=\"--\")\n",
    "plt.title(\"AAPL: Actual vs Predicted Prices (Hybrid RF→LSTM)\")\n",
    "plt.xlabel(\"Time Index (Test Period)\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "savefig(\"actual_vs_predicted_aapl.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b16f9-6c30-48a4-8586-001161cf268d",
   "metadata": {},
   "source": [
    "### 9.2 Scatter Plot of Actual vs Predicted Prices\n",
    "\n",
    "A scatter plot is generated to examine the agreement between actual and predicted prices and identify potential systematic biases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546fcd43-d7f6-4947-88e5-9bcd36a839ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 9.2 Scatter plot (Hybrid – AAPL)\n",
    "# ==================================\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(y_true_h, y_pred_h, alpha=0.6)\n",
    "min_val = min(y_true_h.min(), y_pred_h.min())\n",
    "max_val = max(y_true_h.max(), y_pred_h.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', linewidth=1)\n",
    "\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Actual vs Predicted Scatter Plot (Hybrid RF→LSTM)\")\n",
    "plt.tight_layout()\n",
    "savefig(\"scatter_aapl.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cfa8bf-2876-46bd-b44a-eee6a6d03176",
   "metadata": {},
   "source": [
    "### 9.3 Residual Analysis\n",
    "\n",
    "Residuals are analysed over time to evaluate prediction errors and detect systematic patterns or model bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd548a35-ae98-414a-90d4-5a8bb11b35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 9.3 Residual analysis (Hybrid – AAPL)\n",
    "# ==================================\n",
    "\n",
    "residuals_h = y_true_h - y_pred_h\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(residuals_h)\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "plt.title(\"Residuals over Time (Hybrid RF→LSTM – AAPL)\")\n",
    "plt.xlabel(\"Time Index\")\n",
    "plt.ylabel(\"Prediction Error (USD)\")\n",
    "plt.tight_layout()\n",
    "savefig(\"residuals_aapl.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd270e10-2480-40e3-9b65-fd532480683c",
   "metadata": {},
   "source": [
    "### 9.4 Error Distribution Analysis\n",
    "\n",
    "The distribution of prediction errors is examined to assess the stability and robustness of the hybrid model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61645faa-6e3a-4eeb-87ba-ad636811fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 9.4 Error distribution (Hybrid – AAPL)\n",
    "# ==================================\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(\n",
    "    residuals_h,\n",
    "    bins=35,\n",
    "    color=\"steelblue\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.85\n",
    ")\n",
    "\n",
    "# Reference lines\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1, label=\"Zero Error\")\n",
    "plt.axvline(\n",
    "    residuals_h.mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=1.5,\n",
    "    label=\"Mean Error\"\n",
    ")\n",
    "plt.axvline(\n",
    "    np.median(residuals_h),\n",
    "    color=\"green\",\n",
    "    linestyle=\"-.\",\n",
    "    linewidth=1.5,\n",
    "    label=\"Median Error\"\n",
    ")\n",
    "\n",
    "plt.title(\"Error Distribution of Hybrid RF→LSTM Model (AAPL)\")\n",
    "plt.xlabel(\"Prediction Error (USD)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "savefig(\"error_distribution_aapl.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c65a68-52b5-4c11-8f69-3e3463af31d4",
   "metadata": {},
   "source": [
    "### 9.5 Model Performance Comparison\n",
    "\n",
    "This section compares all implemented models using quantitative evaluation metrics to identify the best-performing approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc09676-be49-474b-8330-effbd6929aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 9.5 Store evaluation metrics explicitly\n",
    "# ==================================\n",
    "\n",
    "# Random Forest – AAPL\n",
    "mae_rf_stock, rmse_rf_stock, mape_rf_stock = regression_metrics(y_test_stock, y_pred_rf_stock)\n",
    "dir_acc_rf_stock = directional_accuracy(y_test_stock, y_pred_rf_stock)\n",
    "\n",
    "# XGBoost – AAPL\n",
    "mae_xgb_stock, rmse_xgb_stock, mape_xgb_stock = regression_metrics(y_test_stock, y_pred_xgb_stock)\n",
    "dir_acc_xgb_stock = directional_accuracy(y_test_stock, y_pred_xgb_stock)\n",
    "\n",
    "# LSTM – AAPL\n",
    "mae_l = mae_l\n",
    "rmse_l = rmse_l\n",
    "mape_l = mape_l\n",
    "dir_acc_l = dir_acc_l\n",
    "\n",
    "# Hybrid RF → LSTM – AAPL\n",
    "mae_h = mae_h\n",
    "rmse_h = rmse_h\n",
    "mape_h = mape_h\n",
    "dir_acc_h = dir_acc_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a364467-85a8-4276-9432-17853b0d54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 9.7 Trading Simulation\n",
    "# ==================================\n",
    "\n",
    "def backtest_trading_strategy(\n",
    "    actual_prices, \n",
    "    predictions, \n",
    "    initial_capital=10000,\n",
    "    transaction_cost=0.001,\n",
    "    strategy_type='regression'\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates realistic trading based on model predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    actual_prices : array-like\n",
    "        Actual closing prices\n",
    "    predictions : array-like\n",
    "        Model predictions (prices for regression, probabilities for classification)\n",
    "    initial_capital : float\n",
    "        Starting capital in USD\n",
    "    transaction_cost : float\n",
    "        Transaction cost as percentage (0.001 = 0.1%)\n",
    "    strategy_type : str\n",
    "        'regression' or 'classification'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Trading results and metrics\n",
    "    \"\"\"\n",
    "    capital = initial_capital\n",
    "    shares = 0\n",
    "    position_value = 0\n",
    "    \n",
    "    portfolio_values = []\n",
    "    trades = []\n",
    "    \n",
    "    for i in range(len(actual_prices) - 1):\n",
    "        current_price = actual_prices[i]\n",
    "        next_price = actual_prices[i + 1]\n",
    "        \n",
    "        # Generate trading signal\n",
    "        if strategy_type == 'regression':\n",
    "            # Buy if predicting price increase\n",
    "            signal = 'buy' if predictions[i + 1] > current_price else 'sell'\n",
    "        else:  # classification\n",
    "            # Buy if predicting up movement (probability > 0.5)\n",
    "            signal = 'buy' if predictions[i] > 0.5 else 'sell'\n",
    "        \n",
    "        # Execute trade\n",
    "        if signal == 'buy' and capital > 0 and shares == 0:\n",
    "            # Buy shares\n",
    "            cost_per_share = current_price * (1 + transaction_cost)\n",
    "            shares = capital / cost_per_share\n",
    "            capital = 0\n",
    "            trades.append({\n",
    "                'day': i,\n",
    "                'action': 'BUY',\n",
    "                'price': current_price,\n",
    "                'shares': shares,\n",
    "                'cost': cost_per_share * shares\n",
    "            })\n",
    "            \n",
    "        elif signal == 'sell' and shares > 0:\n",
    "            # Sell shares\n",
    "            revenue_per_share = current_price * (1 - transaction_cost)\n",
    "            capital = shares * revenue_per_share\n",
    "            trades.append({\n",
    "                'day': i,\n",
    "                'action': 'SELL',\n",
    "                'price': current_price,\n",
    "                'shares': shares,\n",
    "                'revenue': capital\n",
    "            })\n",
    "            shares = 0\n",
    "        \n",
    "        # Calculate portfolio value\n",
    "        if shares > 0:\n",
    "            position_value = shares * current_price\n",
    "        else:\n",
    "            position_value = capital\n",
    "        \n",
    "        portfolio_values.append(position_value)\n",
    "    \n",
    "    # Final liquidation\n",
    "    if shares > 0:\n",
    "        final_price = actual_prices[-1]\n",
    "        capital = shares * final_price * (1 - transaction_cost)\n",
    "        shares = 0\n",
    "    \n",
    "    final_value = capital\n",
    "    portfolio_values.append(final_value)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_return = (final_value / initial_capital - 1) * 100\n",
    "    \n",
    "    # Buy and hold comparison\n",
    "    buy_hold_shares = initial_capital / (actual_prices[0] * (1 + transaction_cost))\n",
    "    buy_hold_final = buy_hold_shares * actual_prices[-1] * (1 - transaction_cost)\n",
    "    buy_hold_return = (buy_hold_final / initial_capital - 1) * 100\n",
    "    \n",
    "    # Calculate Sharpe ratio\n",
    "    portfolio_returns = np.diff(portfolio_values) / portfolio_values[:-1]\n",
    "    sharpe_ratio = np.mean(portfolio_returns) / (np.std(portfolio_returns) + 1e-9) * np.sqrt(252)\n",
    "    \n",
    "    # Calculate maximum drawdown\n",
    "    portfolio_values_arr = np.array(portfolio_values)\n",
    "    running_max = np.maximum.accumulate(portfolio_values_arr)\n",
    "    drawdown = (portfolio_values_arr - running_max) / running_max\n",
    "    max_drawdown = np.min(drawdown) * 100\n",
    "    \n",
    "    return {\n",
    "        'Initial Capital': initial_capital,\n",
    "        'Final Value': final_value,\n",
    "        'Total Return (%)': total_return,\n",
    "        'Buy & Hold Return (%)': buy_hold_return,\n",
    "        'Excess Return (%)': total_return - buy_hold_return,\n",
    "        'Number of Trades': len(trades),\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Max Drawdown (%)': max_drawdown,\n",
    "        'Portfolio Values': portfolio_values,\n",
    "        'Trades': trades\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96d4e5-96e3-46a6-865c-1af05adac293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Hybrid RF→LSTM model (regression)\n",
    "print(\"=\" * 70)\n",
    "print(\"TRADING SIMULATION - HYBRID RF→LSTM (Regression)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Need to align predictions with actual prices\n",
    "# y_true_h has 477 values, y_pred_h has 477 values\n",
    "trading_results_regression = backtest_trading_strategy(\n",
    "    actual_prices=y_true_h,\n",
    "    predictions=y_pred_h,\n",
    "    initial_capital=10000,\n",
    "    transaction_cost=0.001,\n",
    "    strategy_type='regression'\n",
    ")\n",
    "\n",
    "print(f\"Initial Capital:      ${trading_results_regression['Initial Capital']:,.2f}\")\n",
    "print(f\"Final Value:          ${trading_results_regression['Final Value']:,.2f}\")\n",
    "print(f\"Total Return:         {trading_results_regression['Total Return (%)']:.2f}%\")\n",
    "print(f\"Buy & Hold Return:    {trading_results_regression['Buy & Hold Return (%)']:.2f}%\")\n",
    "print(f\"Excess Return:        {trading_results_regression['Excess Return (%)']:.2f}%\")\n",
    "print(f\"Number of Trades:     {trading_results_regression['Number of Trades']}\")\n",
    "print(f\"Sharpe Ratio:         {trading_results_regression['Sharpe Ratio']:.2f}\")\n",
    "print(f\"Max Drawdown:         {trading_results_regression['Max Drawdown (%)']:.2f}%\")\n",
    "\n",
    "# Test with RF Classifier\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRADING SIMULATION - RF CLASSIFIER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "trading_results_classifier = backtest_trading_strategy(\n",
    "    actual_prices=y_test_stock.values,\n",
    "    predictions=y_pred_proba_rf_stock,\n",
    "    initial_capital=10000,\n",
    "    transaction_cost=0.001,\n",
    "    strategy_type='classification'\n",
    ")\n",
    "\n",
    "print(f\"Initial Capital:      ${trading_results_classifier['Initial Capital']:,.2f}\")\n",
    "print(f\"Final Value:          ${trading_results_classifier['Final Value']:,.2f}\")\n",
    "print(f\"Total Return:         {trading_results_classifier['Total Return (%)']:.2f}%\")\n",
    "print(f\"Buy & Hold Return:    {trading_results_classifier['Buy & Hold Return (%)']:.2f}%\")\n",
    "print(f\"Excess Return:        {trading_results_classifier['Excess Return (%)']:.2f}%\")\n",
    "print(f\"Number of Trades:     {trading_results_classifier['Number of Trades']}\")\n",
    "print(f\"Sharpe Ratio:         {trading_results_classifier['Sharpe Ratio']:.2f}\")\n",
    "print(f\"Max Drawdown:         {trading_results_classifier['Max Drawdown (%)']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37c5b7-47a8-4368-84ea-7c51c720f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize portfolio growth\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot 1: Regression Strategy\n",
    "axes[0].plot(\n",
    "    trading_results_regression['Portfolio Values'], \n",
    "    label='Hybrid RF→LSTM Strategy',\n",
    "    linewidth=2\n",
    ")\n",
    "axes[0].axhline(\n",
    "    y=10000, \n",
    "    color='gray', \n",
    "    linestyle='--', \n",
    "    label='Initial Capital',\n",
    "    alpha=0.7\n",
    ")\n",
    "# Buy & Hold line\n",
    "buy_hold_values = 10000 * (y_true_h / y_true_h[0])\n",
    "axes[0].plot(\n",
    "    buy_hold_values, \n",
    "    label='Buy & Hold',\n",
    "    linestyle='--',\n",
    "    alpha=0.7\n",
    ")\n",
    "axes[0].set_title('Portfolio Value - Regression Strategy (AAPL)')\n",
    "axes[0].set_xlabel('Trading Days')\n",
    "axes[0].set_ylabel('Portfolio Value ($)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Classification Strategy\n",
    "axes[1].plot(\n",
    "    trading_results_classifier['Portfolio Values'], \n",
    "    label='RF Classifier Strategy',\n",
    "    linewidth=2,\n",
    "    color='green'\n",
    ")\n",
    "axes[1].axhline(\n",
    "    y=10000, \n",
    "    color='gray', \n",
    "    linestyle='--', \n",
    "    label='Initial Capital',\n",
    "    alpha=0.7\n",
    ")\n",
    "# Buy & Hold line\n",
    "buy_hold_values_clf = 10000 * (y_test_stock.values / y_test_stock.values[0])\n",
    "axes[1].plot(\n",
    "    buy_hold_values_clf, \n",
    "    label='Buy & Hold',\n",
    "    linestyle='--',\n",
    "    alpha=0.7\n",
    ")\n",
    "axes[1].set_title('Portfolio Value - Classification Strategy (AAPL)')\n",
    "axes[1].set_xlabel('Trading Days')\n",
    "axes[1].set_ylabel('Portfolio Value ($)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"trading_simulation_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STRATEGY COMPARISON SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Metric':<30} {'Regression':<15} {'Classification':<15}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Total Return (%)':<30} {trading_results_regression['Total Return (%)']:>14.2f} {trading_results_classifier['Total Return (%)']:>14.2f}\")\n",
    "print(f\"{'Buy & Hold Return (%)':<30} {trading_results_regression['Buy & Hold Return (%)']:>14.2f} {trading_results_classifier['Buy & Hold Return (%)']:>14.2f}\")\n",
    "print(f\"{'Excess Return (%)':<30} {trading_results_regression['Excess Return (%)']:>14.2f} {trading_results_classifier['Excess Return (%)']:>14.2f}\")\n",
    "print(f\"{'Number of Trades':<30} {trading_results_regression['Number of Trades']:>14} {trading_results_classifier['Number of Trades']:>14}\")\n",
    "print(f\"{'Sharpe Ratio':<30} {trading_results_regression['Sharpe Ratio']:>14.2f} {trading_results_classifier['Sharpe Ratio']:>14.2f}\")\n",
    "print(f\"{'Max Drawdown (%)':<30} {trading_results_regression['Max Drawdown (%)']:>14.2f} {trading_results_classifier['Max Drawdown (%)']:>14.2f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56d735-b0cf-4f91-9bb3-238462486769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 9.6 Results comparison table (AAPL)\n",
    "# ==================================\n",
    "\n",
    "results_aapl = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Random Forest\",\n",
    "        \"XGBoost\",\n",
    "        \"LSTM\",\n",
    "        \"Hybrid RF→LSTM\"\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        mae_rf_stock,\n",
    "        mae_xgb_stock,\n",
    "        mae_l,\n",
    "        mae_h\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        rmse_rf_stock,\n",
    "        rmse_xgb_stock,\n",
    "        rmse_l,\n",
    "        rmse_h\n",
    "    ],\n",
    "    \"MAPE (%)\": [\n",
    "        mape_rf_stock,\n",
    "        mape_xgb_stock,\n",
    "        mape_l,\n",
    "        mape_h\n",
    "    ],\n",
    "    \"Directional Accuracy (%)\": [\n",
    "        dir_acc_rf_stock * 100,\n",
    "        dir_acc_xgb_stock * 100,\n",
    "        dir_acc_l * 100,\n",
    "        dir_acc_h * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "results_aapl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4755043-7abc-49fa-98c9-80d8ea82aa7f",
   "metadata": {},
   "source": [
    "## 10. Hybrid RF → LSTM model for cryptocurrency prediction\n",
    "\n",
    "To assess the generalisability of the proposed hybrid framework, the same methodology is applied to cryptocurrency price prediction using Bitcoin (BTC-USD).\n",
    "\n",
    "Cryptocurrency markets differ from equity markets in terms of volatility, trading hours and investor behaviour. Therefore, evaluating the hybrid model\n",
    "on BTC-USD provides an important robustness check.\n",
    "\n",
    "The modelling pipeline remains unchanged to ensure a fair comparison:\n",
    "- Random Forest is used for feature selection\n",
    "- LSTM models temporal dependencies using the selected features\n",
    "- Performance is evaluated on a chronologically held-out test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7b21c-d2d3-4e1e-ae07-df356e61e6e8",
   "metadata": {},
   "source": [
    "### 10.1 Hybrid RF→LSTM Training for Cryptocurrency\n",
    "\n",
    "This section visualises the training and validation loss curves of the hybrid Random Forest → LSTM model for BTC-USD. Monitoring these curves helps assess model convergence, stability and potential overfitting during the training process on cryptocurrency price data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe785c-856b-4cbc-99c8-dfc17b489c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 10.1 Random Forest baseline (BTC)\n",
    "# ==================================\n",
    "\n",
    "rf_crypto = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_crypto.fit(X_train_crypto, y_train_crypto)\n",
    "\n",
    "y_pred_rf_crypto = rf_crypto.predict(X_test_crypto)\n",
    "\n",
    "mae_rf_crypto, rmse_rf_crypto, mape_rf_crypto = regression_metrics(y_test_crypto, y_pred_rf_crypto)\n",
    "dir_acc_rf_crypto = directional_accuracy(y_test_crypto, y_pred_rf_crypto)\n",
    "\n",
    "print(\"Random Forest – BTC-USD\")\n",
    "print(f\"MAE  : {mae_rf_crypto:.4f}\")\n",
    "print(f\"RMSE : {rmse_rf_crypto:.4f}\")\n",
    "print(f\"MAPE : {mape_rf_crypto:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_rf_crypto:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d982fc-605b-434b-a32a-b383bb97728c",
   "metadata": {},
   "source": [
    "### 10.2 Random Forest Baseline Evaluation – BTC-USD\n",
    "\n",
    "A Random Forest regression model is evaluated as a baseline for cryptocurrency price prediction. The performance metrics obtained here serve as a reference point for assessing the effectiveness of the hybrid modelling approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64f22c-521f-49ce-869f-b1db1660559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 10.2 RF feature selection (BTC)\n",
    "# ==================================\n",
    "\n",
    "TOP_N = 10\n",
    "\n",
    "top_features_btc, btc_importance = get_top_features_from_rf(rf_crypto, X_train_crypto.columns, top_n=TOP_N)\n",
    "\n",
    "print(\"Top features (BTC-USD):\")\n",
    "for i, f in enumerate(top_features_btc, start=1):\n",
    "    print(f\"{i}. {f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af453edc-54ff-40bc-b3d3-2de4b3a05672",
   "metadata": {},
   "source": [
    "### 10.3 Feature Importance-Based Feature Selection (BTC-USD)\n",
    "\n",
    "This section identifies the most influential features for BTC-USD prediction using Random Forest feature importance scores. Selected features include both cryptocurrency-specific indicators and cross-market stock indicators, supporting the hypothesis of inter-market relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb124f-dfeb-4f3f-be42-769022d64d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 10.3 Reduce features and scale X & y (BTC)\n",
    "# ==================================\n",
    "\n",
    "X_train_btc_top = X_train_crypto[top_features_btc]\n",
    "X_test_btc_top  = X_test_crypto[top_features_btc]\n",
    "\n",
    "x_scaler_btc = MinMaxScaler()\n",
    "y_scaler_btc = MinMaxScaler()\n",
    "\n",
    "X_train_btc_scaled = x_scaler_btc.fit_transform(X_train_btc_top)\n",
    "X_test_btc_scaled  = x_scaler_btc.transform(X_test_btc_top)\n",
    "\n",
    "y_train_btc_scaled = y_scaler_btc.fit_transform(\n",
    "    y_train_crypto.values.reshape(-1, 1)\n",
    ")\n",
    "y_test_btc_scaled = y_scaler_btc.transform(\n",
    "    y_test_crypto.values.reshape(-1, 1)\n",
    ")\n",
    "\n",
    "print(\"Reduced BTC X_train shape:\", X_train_btc_scaled.shape)\n",
    "print(\"Reduced BTC X_test shape :\", X_test_btc_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b67bab-1450-4872-b17c-90327155fd2f",
   "metadata": {},
   "source": [
    "### 10.4 Reduced Feature Dataset Construction for BTC-USD\n",
    "\n",
    "Based on the selected important features, a reduced feature dataset is created for BTC-USD. This dimensionality reduction aims to improve LSTM efficiency and reduce noise while preserving predictive information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9c9d6-b198-43eb-8e92-5325f03c7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 10.4 Create sequences for hybrid BTC model\n",
    "# ==================================\n",
    "\n",
    "X_train_btc_seq, y_train_btc_seq = create_sequences_xy(\n",
    "    X_train_btc_scaled, y_train_btc_scaled, LOOKBACK_WINDOW\n",
    ")\n",
    "\n",
    "X_test_btc_seq, y_test_btc_seq = create_sequences_xy(\n",
    "    X_test_btc_scaled, y_test_btc_scaled, LOOKBACK_WINDOW\n",
    ")\n",
    "\n",
    "print(\"BTC train sequences:\", X_train_btc_seq.shape, y_train_btc_seq.shape)\n",
    "print(\"BTC test sequences :\", X_test_btc_seq.shape, y_test_btc_seq.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90215aee-973f-44a3-b9ac-064145447c2d",
   "metadata": {},
   "source": [
    "### 10.5 Hybrid RF→LSTM Model Training – Cryptocurrency\n",
    "\n",
    "The hybrid RF→LSTM model is trained on the reduced BTC-USD feature set using time-series sequences. Learning rate scheduling and validation monitoring are applied to enhance training stability and generalisation performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fac184-d190-47d2-85f4-3fcfec2d3cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 10.5 Train hybrid RF → LSTM (BTC)\n",
    "# ==================================\n",
    "\n",
    "hybrid_lstm_btc = build_lstm(\n",
    "    input_shape=(X_train_btc_seq.shape[1], X_train_btc_seq.shape[2])\n",
    ")\n",
    "\n",
    "hybrid_lstm_btc.summary()\n",
    "\n",
    "history_hybrid_btc = hybrid_lstm_btc.fit(\n",
    "    X_train_btc_seq,\n",
    "    y_train_btc_seq,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca01fbd-bebf-4c6b-930f-87b3b4521a89",
   "metadata": {},
   "source": [
    "### 10.6 Hybrid RF→LSTM Model Evaluation – BTC-USD\n",
    "\n",
    "The trained hybrid model is evaluated on unseen BTC-USD test data using multiple error metrics and directional accuracy. The results are compared against baseline models to assess the hybrid model’s effectiveness in handling highly volatile cryptocurrency markets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ebfe4-6923-47ac-bbd6-86d05d09ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 10.6 Evaluate hybrid BTC model\n",
    "# ==================================\n",
    "\n",
    "y_pred_btc_scaled = hybrid_lstm_btc.predict(X_test_btc_seq).flatten()\n",
    "\n",
    "y_pred_btc = y_scaler_btc.inverse_transform(\n",
    "    y_pred_btc_scaled.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "y_true_btc = y_scaler_btc.inverse_transform(\n",
    "    y_test_btc_seq.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "mae_h_btc, rmse_h_btc, mape_h_btc = regression_metrics(\n",
    "    pd.Series(y_true_btc), y_pred_btc\n",
    ")\n",
    "dir_acc_h_btc = directional_accuracy(\n",
    "    pd.Series(y_true_btc), y_pred_btc\n",
    ")\n",
    "\n",
    "print(\"Hybrid RF → LSTM – BTC-USD\")\n",
    "print(f\"MAE  : {mae_h_btc:.4f}\")\n",
    "print(f\"RMSE : {rmse_h_btc:.4f}\")\n",
    "print(f\"MAPE : {mape_h_btc:.2f}%\")\n",
    "print(f\"Directional Accuracy: {dir_acc_h_btc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ce002-785f-469c-a1bd-1063e630153e",
   "metadata": {},
   "source": [
    "### 10.7 Training and Validation Loss Visualisation – BTC-USD\n",
    "\n",
    "This section visualises the training and validation loss curves of the hybrid RF→LSTM model for BTC-USD. The plot provides insight into the model’s learning behaviour, convergence stability and generalisation performance when applied to highly volatile cryptocurrency price data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eafcc70-2b93-403c-b717-1ffc22cf6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 10.7 Hybrid BTC training loss\n",
    "# ==================================\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(history_hybrid_btc.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history_hybrid_btc.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Hybrid RF→LSTM Training Loss (BTC-USD)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "savefig(\"training_loss_btc.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c641db-631d-4bf5-a0a7-010d2a625f24",
   "metadata": {},
   "source": [
    "## 11. Cross-asset performance comparison\n",
    "\n",
    "This section compares the predictive performance of all models across two distinct financial markets: equities (AAPL) and cryptocurrencies (BTC-USD).\n",
    "\n",
    "This section extends the cross-asset results tables by including classical regression baselines and baseline models.These models provide a lower-bound benchmark and strengthen the evaluation framework for hybrid modelling methodology.\n",
    "\n",
    "By analysing error metrics and directional accuracy across asset classes, this comparison evaluates the robustness, generalisability and limitations\n",
    "of the proposed hybrid RF→LSTM framework.\n",
    "\n",
    "Such cross-market evaluation is essential for understanding how marketstructure, volatility and trading behaviour influence predictive performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843daaab-d5a5-47f6-8c51-69fca59cb978",
   "metadata": {},
   "source": [
    "### 11.1 Cross-Asset Performance Comparison\n",
    "\n",
    "Model performance is compared across stock and cryptocurrency markets to analyse differences in predictive behaviour and robustness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2af43a-63e4-4e32-b11a-8a7564f994dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# AAPL model table\n",
    "# ==================================\n",
    "\n",
    "results_aapl_expanded = pd.DataFrame({\n",
    "    \"Asset\": [\"AAPL\"] * 7,\n",
    "    \"Model\": [\n",
    "        \"Linear Regression\",\n",
    "        \"Ridge Regression\",\n",
    "        \"SVR (RBF)\",\n",
    "        \"Random Forest\",\n",
    "        \"XGBoost\",\n",
    "        \"LSTM\",\n",
    "        \"Hybrid RF→LSTM\"\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        mae_lr_stock,\n",
    "        mae_ridge_stock,\n",
    "        mae_svr_stock,\n",
    "        mae_rf_stock,\n",
    "        mae_xgb_stock,\n",
    "        mae_l,\n",
    "        mae_h\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        rmse_lr_stock,\n",
    "        rmse_ridge_stock,\n",
    "        rmse_svr_stock,\n",
    "        rmse_rf_stock,\n",
    "        rmse_xgb_stock,\n",
    "        rmse_l,\n",
    "        rmse_h\n",
    "    ],\n",
    "    \"MAPE (%)\": [\n",
    "        mape_lr_stock,\n",
    "        mape_ridge_stock,\n",
    "        mape_svr_stock,\n",
    "        mape_rf_stock,\n",
    "        mape_xgb_stock,\n",
    "        mape_l,\n",
    "        mape_h\n",
    "    ],\n",
    "    \"Directional Accuracy (%)\": [\n",
    "        dir_acc_lr_stock * 100,\n",
    "        dir_acc_ridge_stock * 100,\n",
    "        dir_acc_svr_stock * 100,\n",
    "        dir_acc_rf_stock * 100,\n",
    "        dir_acc_xgb_stock * 100,\n",
    "        dir_acc_l * 100,\n",
    "        dir_acc_h * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "results_aapl_expanded\n",
    "\n",
    "# ==================================\n",
    "# BTC-USD model table\n",
    "# ==================================\n",
    "\n",
    "results_btc_minimal = pd.DataFrame({\n",
    "    \"Asset\": [\"BTC-USD\", \"BTC-USD\"],\n",
    "    \"Model\": [\"Random Forest\", \"Hybrid RF→LSTM\"],\n",
    "    \"MAE\": [mae_rf_crypto, mae_h_btc],\n",
    "    \"RMSE\": [rmse_rf_crypto, rmse_h_btc],\n",
    "    \"MAPE (%)\": [mape_rf_crypto, mape_h_btc],\n",
    "    \"Directional Accuracy (%)\": [dir_acc_rf_crypto * 100, dir_acc_h_btc * 100]\n",
    "})\n",
    "\n",
    "# ==================================\n",
    "# Combined model table\n",
    "# ==================================\n",
    "results_combined_expanded = pd.concat(\n",
    "    [results_aapl_expanded, results_btc_minimal],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "results_combined_expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03c9d5-4188-4e8e-9c7d-9c66a29d0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 11.1 Comprehensive Model Comparison \n",
    "# ==================================\n",
    "\n",
    "# Create comprehensive results table\n",
    "results_comprehensive = pd.DataFrame({\n",
    "    \"Asset\": [\"AAPL\"] * 9 + [\"BTC-USD\"] * 2,\n",
    "    \"Model\": [\n",
    "        \"Linear Regression\",\n",
    "        \"Ridge Regression\",\n",
    "        \"SVR (RBF)\",\n",
    "        \"Random Forest (Reg)\",\n",
    "        \"XGBoost (Reg)\",\n",
    "        \"LSTM (Reg)\",\n",
    "        \"Hybrid RF→LSTM (Reg)\",\n",
    "        \"Random Forest (Clf)\",\n",
    "        \"LSTM (Clf)\",\n",
    "        \"Random Forest (Reg)\",\n",
    "        \"Hybrid RF→LSTM (Reg)\"\n",
    "    ],\n",
    "    \"Task\": [\n",
    "        \"Regression\", \"Regression\", \"Regression\", \"Regression\", \"Regression\",\n",
    "        \"Regression\", \"Regression\", \"Classification\", \"Classification\",\n",
    "        \"Regression\", \"Regression\"\n",
    "    ],\n",
    "    \"MAE\": [\n",
    "        mae_lr_stock, mae_ridge_stock, mae_svr_stock,\n",
    "        mae_rf_stock, mae_xgb_stock, mae_l, mae_h,\n",
    "        np.nan, np.nan,  # Classification doesn't have MAE\n",
    "        mae_rf_crypto, mae_h_btc\n",
    "    ],\n",
    "    \"RMSE\": [\n",
    "        rmse_lr_stock, rmse_ridge_stock, rmse_svr_stock,\n",
    "        rmse_rf_stock, rmse_xgb_stock, rmse_l, rmse_h,\n",
    "        np.nan, np.nan,  # Classification doesn't have RMSE\n",
    "        rmse_rf_crypto, rmse_h_btc\n",
    "    ],\n",
    "    \"MAPE (%)\": [\n",
    "        mape_lr_stock, mape_ridge_stock, mape_svr_stock,\n",
    "        mape_rf_stock, mape_xgb_stock, mape_l, mape_h,\n",
    "        np.nan, np.nan,  # Classification doesn't have MAPE\n",
    "        mape_rf_crypto, mape_h_btc\n",
    "    ],\n",
    "    \"Accuracy/Dir_Acc (%)\": [\n",
    "        dir_acc_lr_stock * 100,\n",
    "        dir_acc_ridge_stock * 100,\n",
    "        dir_acc_svr_stock * 100,\n",
    "        dir_acc_rf_stock * 100,\n",
    "        dir_acc_xgb_stock * 100,\n",
    "        dir_acc_l * 100,\n",
    "        dir_acc_h * 100,\n",
    "        acc_rf_stock * 100,  # Classification accuracy\n",
    "        acc_lstm_clf * 100,  # Classification accuracy\n",
    "        dir_acc_rf_crypto * 100,\n",
    "        dir_acc_h_btc * 100\n",
    "    ],\n",
    "    \"F1-Score\": [\n",
    "        np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,\n",
    "        f1_rf_stock,  # Classification F1\n",
    "        f1_lstm_clf,  # Classification F1\n",
    "        np.nan, np.nan\n",
    "    ],\n",
    "    \"ROC AUC\": [\n",
    "        np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,\n",
    "        auc_rf_stock,  # Classification AUC\n",
    "        auc_lstm_clf,  # Classification AUC\n",
    "        np.nan, np.nan\n",
    "    ]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a9cbb-7b86-42da-8550-1fdcee5e5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the table for display\n",
    "results_display = results_comprehensive.copy()\n",
    "\n",
    "# Format numeric columns\n",
    "results_display[\"MAE\"] = results_display[\"MAE\"].apply(\n",
    "    lambda x: f\"{x:.4f}\" if pd.notna(x) else \"-\"\n",
    ")\n",
    "results_display[\"RMSE\"] = results_display[\"RMSE\"].apply(\n",
    "    lambda x: f\"{x:.4f}\" if pd.notna(x) else \"-\"\n",
    ")\n",
    "results_display[\"MAPE (%)\"] = results_display[\"MAPE (%)\"].apply(\n",
    "    lambda x: f\"{x:.2f}\" if pd.notna(x) else \"-\"\n",
    ")\n",
    "results_display[\"Accuracy/Dir_Acc (%)\"] = results_display[\"Accuracy/Dir_Acc (%)\"].apply(\n",
    "    lambda x: f\"{x:.2f}\" if pd.notna(x) else \"-\"\n",
    ")\n",
    "results_display[\"F1-Score\"] = results_display[\"F1-Score\"].apply(\n",
    "    lambda x: f\"{x:.4f}\" if pd.notna(x) else \"-\"\n",
    ")\n",
    "results_display[\"ROC AUC\"] = results_display[\"ROC AUC\"].apply(\n",
    "    lambda x: f\"{x:.4f}\" if pd.notna(x) else \"-\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 120)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON TABLE\")\n",
    "print(\"=\" * 120)\n",
    "display(results_display)\n",
    "\n",
    "# Highlight best performers\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"BEST PERFORMERS BY METRIC\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "# Regression metrics (AAPL only)\n",
    "reg_mask = (results_comprehensive[\"Asset\"] == \"AAPL\") & (results_comprehensive[\"Task\"] == \"Regression\")\n",
    "reg_results = results_comprehensive[reg_mask]\n",
    "\n",
    "best_mae = reg_results.loc[reg_results[\"MAE\"].idxmin()]\n",
    "best_rmse = reg_results.loc[reg_results[\"RMSE\"].idxmin()]\n",
    "best_mape = reg_results.loc[reg_results[\"MAPE (%)\"].idxmin()]\n",
    "\n",
    "print(\"\\nRegression Task (AAPL):\")\n",
    "print(f\"  Best MAE:  {best_mae['Model']:<25} ({best_mae['MAE']:.4f})\")\n",
    "print(f\"  Best RMSE: {best_rmse['Model']:<25} ({best_rmse['RMSE']:.4f})\")\n",
    "print(f\"  Best MAPE: {best_mape['Model']:<25} ({best_mape['MAPE (%)']:.2f}%)\")\n",
    "\n",
    "# Classification metrics (AAPL only)\n",
    "clf_mask = (results_comprehensive[\"Asset\"] == \"AAPL\") & (results_comprehensive[\"Task\"] == \"Classification\")\n",
    "clf_results = results_comprehensive[clf_mask]\n",
    "\n",
    "best_acc = clf_results.loc[clf_results[\"Accuracy/Dir_Acc (%)\"].idxmax()]\n",
    "best_f1 = clf_results.loc[clf_results[\"F1-Score\"].idxmax()]\n",
    "best_auc = clf_results.loc[clf_results[\"ROC AUC\"].idxmax()]\n",
    "\n",
    "print(\"\\nClassification Task (AAPL):\")\n",
    "print(f\"  Best Accuracy: {best_acc['Model']:<25} ({best_acc['Accuracy/Dir_Acc (%)']:.2f}%)\")\n",
    "print(f\"  Best F1-Score: {best_f1['Model']:<25} ({best_f1['F1-Score']:.4f})\")\n",
    "print(f\"  Best ROC AUC:  {best_auc['Model']:<25} ({best_auc['ROC AUC']:.4f})\")\n",
    "\n",
    "print(\"=\" * 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b5fb3-2e7d-498f-bcd0-6edddd05f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization comparing regression vs classification\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: MAE Comparison (Regression only)\n",
    "reg_models = reg_results[\"Model\"].str.replace(\" (Reg)\", \"\", regex=False)\n",
    "mae_values = reg_results[\"MAE\"].values\n",
    "axes[0, 0].barh(reg_models, mae_values, color='steelblue')\n",
    "axes[0, 0].set_xlabel('MAE')\n",
    "axes[0, 0].set_title('Mean Absolute Error (AAPL - Regression Models)')\n",
    "axes[0, 0].invert_yaxis()\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Highlight best\n",
    "best_idx = np.argmin(mae_values)\n",
    "axes[0, 0].get_children()[best_idx].set_color('darkgreen')\n",
    "\n",
    "# Plot 2: Directional Accuracy (Regression)\n",
    "dir_acc_values = reg_results[\"Accuracy/Dir_Acc (%)\"].values\n",
    "axes[0, 1].barh(reg_models, dir_acc_values, color='coral')\n",
    "axes[0, 1].axvline(x=50, color='red', linestyle='--', label='Random (50%)', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Directional Accuracy (%)')\n",
    "axes[0, 1].set_title('Directional Accuracy (AAPL - Regression Models)')\n",
    "axes[0, 1].invert_yaxis()\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 3: Classification Accuracy\n",
    "clf_models = clf_results[\"Model\"].str.replace(\" (Clf)\", \"\", regex=False)\n",
    "clf_acc_values = clf_results[\"Accuracy/Dir_Acc (%)\"].values\n",
    "axes[1, 0].barh(clf_models, clf_acc_values, color='green')\n",
    "axes[1, 0].axvline(x=50, color='red', linestyle='--', label='Random (50%)', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Classification Accuracy (%)')\n",
    "axes[1, 0].set_title('Classification Accuracy (AAPL - Classification Models)')\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Highlight best\n",
    "best_clf_idx = np.argmax(clf_acc_values)\n",
    "axes[1, 0].get_children()[best_clf_idx].set_color('darkgreen')\n",
    "\n",
    "# Plot 4: ROC AUC Comparison\n",
    "auc_values = clf_results[\"ROC AUC\"].values\n",
    "axes[1, 1].barh(clf_models, auc_values, color='purple')\n",
    "axes[1, 1].axvline(x=0.5, color='red', linestyle='--', label='Random (0.5)', alpha=0.7)\n",
    "axes[1, 1].set_xlabel('ROC AUC')\n",
    "axes[1, 1].set_title('ROC AUC Score (AAPL - Classification Models)')\n",
    "axes[1, 1].set_xlim([0, 1])\n",
    "axes[1, 1].invert_yaxis()\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Highlight best\n",
    "best_auc_idx = np.argmax(auc_values)\n",
    "axes[1, 1].get_children()[best_auc_idx].set_color('darkgreen')\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"comprehensive_model_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea8103-3970-4e2a-bfed-3e89cc6296c5",
   "metadata": {},
   "source": [
    "### 11.2 Relative Improvement Analysis\n",
    "\n",
    "This section quantifies the relative improvement of the hybrid model over baseline approaches using percentage-based metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d965feb-9395-4217-ba3c-6682cd771224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 11.2 Relative improvement (%) vs Random Forest\n",
    "# ==================================\n",
    "\n",
    "improvement = pd.DataFrame({\n",
    "    \"Asset\": [\"AAPL\", \"BTC-USD\"],\n",
    "    \"MAE Improvement (%)\": [\n",
    "        (1 - mae_h / mae_rf_stock) * 100,\n",
    "        (1 - mae_h_btc / mae_rf_crypto) * 100\n",
    "    ],\n",
    "    \"RMSE Improvement (%)\": [\n",
    "        (1 - rmse_h / rmse_rf_stock) * 100,\n",
    "        (1 - rmse_h_btc / rmse_rf_crypto) * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8889d81-8335-42cf-8a0b-0a1227a633fd",
   "metadata": {},
   "source": [
    "### 11.3 Visual Comparison of Hybrid Model Gains\n",
    "\n",
    "A bar chart visualises the performance gains achieved by the hybrid model across different asset classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e5d82-c7ac-4ac1-b249-f664fa2995a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 11.3 Visual comparison of hybrid gains\n",
    "# ==================================\n",
    "\n",
    "improvement.set_index(\"Asset\").plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(7, 4)\n",
    ")\n",
    "\n",
    "plt.title(\"Hybrid RF→LSTM Improvement over Random Forest\")\n",
    "plt.ylabel(\"Improvement (%)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "savefig(\"hybrid_improvement_rf.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb51f14",
   "metadata": {},
   "source": [
    "## 11.4 Robust evaluation additions (naïve baseline & walk-forward validation)\n",
    "\n",
    "To strengthen the validity of the findings for a time-series forecasting task, this section adds two widely used evaluation components:\n",
    "\n",
    "- **Naïve (persistence) baseline:** tomorrow's close is assumed to be today's close. This is a strong baseline in financial time series and helps contextualise model performance.\n",
    "- **Walk-forward (TimeSeriesSplit) validation:** classical ML models are evaluated over multiple chronological folds to reduce dependence on a single train/test split.\n",
    "\n",
    "> Note: Deep learning models (LSTM / Hybrid) can be computationally expensive to re-train across many folds. Therefore, walk-forward validation is applied to the classical ML baselines, while LSTM/Hybrid results are reported on the fixed holdout split used throughout the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba83a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 11.4.1 Utility: unified metrics + naïve baseline\n",
    "# ==================================\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def regression_metrics_dict(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # avoid division by zero in MAPE\n",
    "    denom = np.where(np.abs(y_true) < 1e-9, 1e-9, np.abs(y_true))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "    dir_acc = directional_accuracy(pd.Series(y_true), pd.Series(y_pred))\n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE_%\": mape,\n",
    "        \"Directional_Acc\": dir_acc\n",
    "    }\n",
    "\n",
    "def naive_persistence_forecast(y_train, y_test):\n",
    "    \"\"\"Predicts y[t] as y[t-1]. For the first test point, uses last train value.\"\"\"\n",
    "    y_train = pd.Series(y_train).reset_index(drop=True)\n",
    "    y_test = pd.Series(y_test).reset_index(drop=True)\n",
    "    y_pred = y_test.shift(1)\n",
    "    y_pred.iloc[0] = y_train.iloc[-1]\n",
    "    return y_pred.values\n",
    "\n",
    "# Naïve baseline (AAPL)\n",
    "y_pred_naive_stock = naive_persistence_forecast(y_train_stock, y_test_stock)\n",
    "naive_stock_metrics = regression_metrics_dict(y_test_stock, y_pred_naive_stock)\n",
    "\n",
    "print(\"Naïve (Persistence) Baseline – AAPL\")\n",
    "for k,v in naive_stock_metrics.items():\n",
    "    if k == \"Directional_Acc\":\n",
    "        print(f\"{k}: {v:.2%}\")\n",
    "    elif k == \"MAPE_%\":\n",
    "        print(f\"{k}: {v:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# Naïve baseline (BTC)\n",
    "y_pred_naive_crypto = naive_persistence_forecast(y_train_crypto, y_test_crypto)\n",
    "naive_crypto_metrics = regression_metrics_dict(y_test_crypto, y_pred_naive_crypto)\n",
    "\n",
    "print(\"\\nNaïve (Persistence) Baseline – BTC-USD\")\n",
    "for k,v in naive_crypto_metrics.items():\n",
    "    if k == \"Directional_Acc\":\n",
    "        print(f\"{k}: {v:.2%}\")\n",
    "    elif k == \"MAPE_%\":\n",
    "        print(f\"{k}: {v:.2f}%\")\n",
    "    else:\n",
    "        print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 11.4.2 Walk-forward validation for classical ML baselines\n",
    "# ==================================\n",
    "# This evaluates each model over multiple chronological folds.\n",
    "# It is especially useful for financial time series where regime changes occur.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from scipy.linalg import LinAlgWarning\n",
    "import warnings\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def walk_forward_cv(model, X_df, y_series, name=\"model\"):\n",
    "    fold_rows = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X_df), start=1):\n",
    "        X_tr, X_te = X_df.iloc[train_idx], X_df.iloc[test_idx]\n",
    "        y_tr, y_te = y_series.iloc[train_idx], y_series.iloc[test_idx]\n",
    "\n",
    "        m = clone(model)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=LinAlgWarning)\n",
    "            m.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred = m.predict(X_te)\n",
    "        metrics = regression_metrics_dict(y_te, y_pred)\n",
    "        metrics[\"Fold\"] = fold\n",
    "        fold_rows.append(metrics)\n",
    "\n",
    "    df = pd.DataFrame(fold_rows)\n",
    "    summary = df.drop(columns=[\"Fold\"]).mean(numeric_only=True).to_dict()\n",
    "    print(f\"{name} walk-forward CV (mean over {tscv.get_n_splits()} folds)\")\n",
    "    for k, v in summary.items():\n",
    "        if k == \"Directional_Acc\":\n",
    "            print(f\"  {k}: {v:.2%}\")\n",
    "        elif k == \"MAPE_%\":\n",
    "            print(f\"  {k}: {v:.2f}%\")\n",
    "        else:\n",
    "            print(f\"  {k}: {v:.4f}\")\n",
    "    return df, summary\n",
    "\n",
    "\n",
    "# Define baseline models for CV\n",
    "baseline_models = {\n",
    "    \"LinearRegression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LinearRegression())\n",
    "    ]),\n",
    "    \"Ridge\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"ridge\", Ridge(alpha=10.0))  # slightly stronger regularisation improves stability\n",
    "    ]),\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=300, random_state=SEED, n_jobs=-1, max_depth=None, min_samples_leaf=1\n",
    "    ),\n",
    "    \"SVR(RBF)\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svr\", SVR(kernel=\"rbf\", C=50, gamma=\"scale\", epsilon=0.1))\n",
    "    ])\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    baseline_models[\"XGBoost\"] = XGBRegressor(\n",
    "        n_estimators=500, learning_rate=0.05, max_depth=5,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=SEED, n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Run walk-forward CV for AAPL and BTC\n",
    "cv_results = {}\n",
    "\n",
    "print(\"\\n--- Walk-forward CV: AAPL ---\")\n",
    "for name, model in baseline_models.items():\n",
    "    df_folds, summary = walk_forward_cv(model, X, y_stock, name)\n",
    "    cv_results[(\"AAPL\", name)] = summary\n",
    "\n",
    "print(\"\\n--- Walk-forward CV: BTC-USD ---\")\n",
    "for name, model in baseline_models.items():\n",
    "    df_folds, summary = walk_forward_cv(model, X, y_crypto, name)\n",
    "    cv_results[(\"BTC\", name)] = summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8bacb1",
   "metadata": {},
   "source": [
    "### 11.4.3 Compact summary table (naïve baseline + walk-forward CV)\n",
    "\n",
    "The table below combines:\n",
    "- the **naïve baseline** performance on the holdout split, and\n",
    "- the **walk-forward CV mean** scores for classical ML models.\n",
    "\n",
    "Use this table in Chapter 4 (Results) to support stronger, more defensible comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8173e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build summary table\n",
    "rows = []\n",
    "\n",
    "# Naïve baselines\n",
    "rows.append({\"Asset\": \"AAPL\", \"Model\": \"Naïve (Persistence)\", **naive_stock_metrics})\n",
    "rows.append({\"Asset\": \"BTC\", \"Model\": \"Naïve (Persistence)\", **naive_crypto_metrics})\n",
    "\n",
    "# CV means\n",
    "for (asset, name), summary in cv_results.items():\n",
    "    rows.append({\"Asset\": asset, \"Model\": f\"{name} (CV mean)\", **summary})\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "summary_df[\"Directional_Acc\"] = summary_df[\"Directional_Acc\"].apply(lambda x: f\"{x:.2%}\")\n",
    "summary_df[\"MAE\"] = summary_df[\"MAE\"].map(lambda x: f\"{x:.4f}\")\n",
    "summary_df[\"RMSE\"] = summary_df[\"RMSE\"].map(lambda x: f\"{x:.4f}\")\n",
    "summary_df[\"MAPE_%\"] = summary_df[\"MAPE_%\"].map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a744e6b-d8d4-4f0a-a5c0-50add7c6f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 11.5 Market Regime Analysis (NEW)\n",
    "# ==================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MARKET REGIME ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def analyze_by_market_regime(y_true, y_pred, prices, window=20):\n",
    "    \"\"\"\n",
    "    Evaluates model performance in different market conditions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True values\n",
    "    y_pred : array-like\n",
    "        Predicted values\n",
    "    prices : array-like\n",
    "        Actual prices for regime detection\n",
    "    window : int\n",
    "        Window for calculating trend\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Performance metrics by regime\n",
    "    \"\"\"\n",
    "    # Calculate price momentum\n",
    "    returns = pd.Series(prices).pct_change()\n",
    "    momentum = returns.rolling(window).mean()\n",
    "    \n",
    "    # Define regimes\n",
    "    bull_mask = (momentum > 0.001).values  # Uptrend\n",
    "    bear_mask = (momentum < -0.001).values  # Downtrend\n",
    "    sideways_mask = (~bull_mask & ~bear_mask)  # Sideways\n",
    "    \n",
    "    # Remove NaN from rolling calculation\n",
    "    valid_idx = ~momentum.isna()\n",
    "    \n",
    "    def calc_metrics(mask):\n",
    "        mask_valid = mask & valid_idx\n",
    "        if mask_valid.sum() < 5:  # Need at least 5 samples\n",
    "            return None\n",
    "        \n",
    "        y_t = y_true[mask_valid]\n",
    "        y_p = y_pred[mask_valid]\n",
    "        \n",
    "        mae = mean_absolute_error(y_t, y_p)\n",
    "        rmse = np.sqrt(mean_squared_error(y_t, y_p))\n",
    "        mape = np.mean(np.abs((y_t - y_p) / (y_t + 1e-9))) * 100\n",
    "        dir_acc = directional_accuracy(pd.Series(y_t), pd.Series(y_p))\n",
    "        \n",
    "        return {\n",
    "            'Count': mask_valid.sum(),\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'MAPE (%)': mape,\n",
    "            'Dir_Acc (%)': dir_acc * 100\n",
    "        }\n",
    "    \n",
    "    bull_metrics = calc_metrics(bull_mask)\n",
    "    bear_metrics = calc_metrics(bear_mask)\n",
    "    sideways_metrics = calc_metrics(sideways_mask)\n",
    "    \n",
    "    return {\n",
    "        'Bull Market': bull_metrics,\n",
    "        'Bear Market': bear_metrics,\n",
    "        'Sideways Market': sideways_metrics,\n",
    "        'Bull %': (bull_mask & valid_idx).sum() / valid_idx.sum() * 100,\n",
    "        'Bear %': (bear_mask & valid_idx).sum() / valid_idx.sum() * 100,\n",
    "        'Sideways %': (sideways_mask & valid_idx).sum() / valid_idx.sum() * 100\n",
    "    }\n",
    "\n",
    "# Analyze Hybrid RF→LSTM (Regression)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"HYBRID RF→LSTM - MARKET REGIME ANALYSIS (AAPL)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "regime_results = analyze_by_market_regime(\n",
    "    y_true=y_true_h,\n",
    "    y_pred=y_pred_h,\n",
    "    prices=y_true_h,\n",
    "    window=20\n",
    ")\n",
    "\n",
    "print(f\"\\nMarket Distribution:\")\n",
    "print(f\"  Bull Market:     {regime_results['Bull %']:.1f}%\")\n",
    "print(f\"  Bear Market:     {regime_results['Bear %']:.1f}%\")\n",
    "print(f\"  Sideways Market: {regime_results['Sideways %']:.1f}%\")\n",
    "\n",
    "regime_df = pd.DataFrame({\n",
    "    'Regime': ['Bull Market', 'Bear Market', 'Sideways Market'],\n",
    "    'Sample Count': [\n",
    "        regime_results['Bull Market']['Count'],\n",
    "        regime_results['Bear Market']['Count'],\n",
    "        regime_results['Sideways Market']['Count']\n",
    "    ],\n",
    "    'MAE': [\n",
    "        regime_results['Bull Market']['MAE'],\n",
    "        regime_results['Bear Market']['MAE'],\n",
    "        regime_results['Sideways Market']['MAE']\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        regime_results['Bull Market']['RMSE'],\n",
    "        regime_results['Bear Market']['RMSE'],\n",
    "        regime_results['Sideways Market']['RMSE']\n",
    "    ],\n",
    "    'MAPE (%)': [\n",
    "        regime_results['Bull Market']['MAPE (%)'],\n",
    "        regime_results['Bear Market']['MAPE (%)'],\n",
    "        regime_results['Sideways Market']['MAPE (%)']\n",
    "    ],\n",
    "    'Dir_Acc (%)': [\n",
    "        regime_results['Bull Market']['Dir_Acc (%)'],\n",
    "        regime_results['Bear Market']['Dir_Acc (%)'],\n",
    "        regime_results['Sideways Market']['Dir_Acc (%)']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nPerformance by Market Regime:\")\n",
    "display(regime_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b223cb51-4433-45f5-9d92-52f5caa6ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regime performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: MAE by Regime\n",
    "regimes = ['Bull', 'Bear', 'Sideways']\n",
    "mae_by_regime = [\n",
    "    regime_results['Bull Market']['MAE'],\n",
    "    regime_results['Bear Market']['MAE'],\n",
    "    regime_results['Sideways Market']['MAE']\n",
    "]\n",
    "axes[0, 0].bar(regimes, mae_by_regime, color=['green', 'red', 'gray'])\n",
    "axes[0, 0].set_ylabel('MAE')\n",
    "axes[0, 0].set_title('MAE by Market Regime')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: RMSE by Regime\n",
    "rmse_by_regime = [\n",
    "    regime_results['Bull Market']['RMSE'],\n",
    "    regime_results['Bear Market']['RMSE'],\n",
    "    regime_results['Sideways Market']['RMSE']\n",
    "]\n",
    "axes[0, 1].bar(regimes, rmse_by_regime, color=['green', 'red', 'gray'])\n",
    "axes[0, 1].set_ylabel('RMSE')\n",
    "axes[0, 1].set_title('RMSE by Market Regime')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: MAPE by Regime\n",
    "mape_by_regime = [\n",
    "    regime_results['Bull Market']['MAPE (%)'],\n",
    "    regime_results['Bear Market']['MAPE (%)'],\n",
    "    regime_results['Sideways Market']['MAPE (%)']\n",
    "]\n",
    "axes[1, 0].bar(regimes, mape_by_regime, color=['green', 'red', 'gray'])\n",
    "axes[1, 0].set_ylabel('MAPE (%)')\n",
    "axes[1, 0].set_title('MAPE by Market Regime')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Directional Accuracy by Regime\n",
    "dir_acc_by_regime = [\n",
    "    regime_results['Bull Market']['Dir_Acc (%)'],\n",
    "    regime_results['Bear Market']['Dir_Acc (%)'],\n",
    "    regime_results['Sideways Market']['Dir_Acc (%)']\n",
    "]\n",
    "axes[1, 1].bar(regimes, dir_acc_by_regime, color=['green', 'red', 'gray'])\n",
    "axes[1, 1].axhline(y=50, color='black', linestyle='--', label='Random (50%)', alpha=0.7)\n",
    "axes[1, 1].set_ylabel('Directional Accuracy (%)')\n",
    "axes[1, 1].set_title('Directional Accuracy by Market Regime')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"market_regime_analysis.png\")\n",
    "plt.show()\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_regime_mae = regimes[np.argmin(mae_by_regime)]\n",
    "worst_regime_mae = regimes[np.argmax(mae_by_regime)]\n",
    "best_regime_dir = regimes[np.argmax(dir_acc_by_regime)]\n",
    "\n",
    "print(f\"✓ Best MAE performance:        {best_regime_mae} Market ({min(mae_by_regime):.4f})\")\n",
    "print(f\"✗ Worst MAE performance:       {worst_regime_mae} Market ({max(mae_by_regime):.4f})\")\n",
    "print(f\"✓ Best directional accuracy:   {best_regime_dir} Market ({max(dir_acc_by_regime):.2f}%)\")\n",
    "print(f\"  Model performs {max(mae_by_regime)/min(mae_by_regime):.2f}x worse in {worst_regime_mae} markets\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27915452-88c6-4398-89fb-70cf59d09475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 11.6 Statistical Significance Testing \n",
    "# ==================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "def test_model_significance(y_true, y_pred1, y_pred2,\n",
    "                            model1_name=\"Model 1\",\n",
    "                            model2_name=\"Model 2\"):\n",
    "    \"\"\"\n",
    "    Paired statistical comparison of two regression models\n",
    "    using absolute prediction errors.\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred1 = np.asarray(y_pred1).ravel()\n",
    "    y_pred2 = np.asarray(y_pred2).ravel()\n",
    "\n",
    "    assert len(y_true) == len(y_pred1) == len(y_pred2), \\\n",
    "        \"Arrays must be aligned and of equal length.\"\n",
    "\n",
    "    # Absolute errors (paired by time index)\n",
    "    err1 = np.abs(y_true - y_pred1)\n",
    "    err2 = np.abs(y_true - y_pred2)\n",
    "\n",
    "    # Paired t-test\n",
    "    t_stat, p_t = ttest_rel(err1, err2)\n",
    "\n",
    "    # Wilcoxon signed-rank test (robust alternative)\n",
    "    try:\n",
    "        w_stat, p_w = wilcoxon(err1, err2)\n",
    "    except ValueError:\n",
    "        p_w = np.nan\n",
    "\n",
    "    # Effect size (Cohen's d for paired samples)\n",
    "    diff = err1 - err2\n",
    "    cohens_d = diff.mean() / (diff.std(ddof=1) + 1e-12)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"STATISTICAL SIGNIFICANCE TEST: {model1_name} vs {model2_name}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Mean absolute error ({model1_name}): {err1.mean():.4f}\")\n",
    "    print(f\"Mean absolute error ({model2_name}): {err2.mean():.4f}\")\n",
    "    print(f\"Mean difference (err1 - err2): {diff.mean():.4f}\")\n",
    "    print(f\"Paired t-test p-value: {p_t:.6f}\")\n",
    "    print(f\"Wilcoxon p-value: {p_w:.6f}\" if not np.isnan(p_w) else \"Wilcoxon p-value: N/A\")\n",
    "    print(f\"Cohen’s d (paired): {cohens_d:.4f}\")\n",
    "\n",
    "    if p_t < 0.05:\n",
    "        print(\"Interpretation: Difference is statistically significant at α = 0.05.\")\n",
    "    else:\n",
    "        print(\"Interpretation: Difference is not statistically significant at α = 0.05.\")\n",
    "\n",
    "    return {\n",
    "        \"Comparison\": f\"{model1_name} vs {model2_name}\",\n",
    "        \"MAE_\" + model1_name: err1.mean(),\n",
    "        \"MAE_\" + model2_name: err2.mean(),\n",
    "        \"Mean_Diff\": diff.mean(),\n",
    "        \"p_ttest\": p_t,\n",
    "        \"p_wilcoxon\": p_w,\n",
    "        \"cohens_d\": cohens_d\n",
    "    }\n",
    "\n",
    "# Get the last 477 predictions from RF to match hybrid\n",
    "rf_predictions_aligned = y_pred_rf_stock[-len(y_true_h):]\n",
    "y_test_aligned = y_test_stock.values[-len(y_true_h):]\n",
    "\n",
    "# -------------------------\n",
    "# Test 1: Random Forest vs Hybrid\n",
    "# -------------------------\n",
    "sig_test1 = test_model_significance(\n",
    "    y_true=y_true_h,\n",
    "    y_pred1=rf_predictions_aligned,\n",
    "    y_pred2=y_pred_h,\n",
    "    model1_name=\"Random Forest\",\n",
    "    model2_name=\"Hybrid RF→LSTM\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Test 2: LSTM vs Hybrid \n",
    "# -------------------------\n",
    "sig_test2 = test_model_significance(\n",
    "    y_true=y_true_lstm,\n",
    "    y_pred1=y_pred_lstm,\n",
    "    y_pred2=y_pred_h,\n",
    "    model1_name=\"LSTM\",\n",
    "    model2_name=\"Hybrid RF→LSTM\"\n",
    ")\n",
    "\n",
    "# Summary table \n",
    "sig_results_df = pd.DataFrame([sig_test1, sig_test2])\n",
    "sig_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224c30c-fea5-4eca-9337-530d99087c30",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "This project investigated the effectiveness of machine learning and deep learning models for predicting stock and cryptocurrency prices using publicly available financial data. Using Apple Inc. (AAPL) as a representative stock and Bitcoin (BTC-USD) as a representative cryptocurrency, multiple models were implemented and evaluated including Random Forest, XGBoost, Support Vector Regression, LSTM and a hybrid Random Forest–LSTM approach.\n",
    "\n",
    "The experimental results showed that traditional machine learning models such as Random Forest and XGBoost were able to capture basic price-level patterns but struggled to consistently predict short-term market direction. The LSTM model which incorporates temporal dependencies, demonstrated improved ability to follow overall price trends. The proposed hybrid approach which combines Random Forest-based feature selection with LSTM sequence learning, achieved better error-based performance metrics such as MAE, RMSE and MAPE, particularly for the cryptocurrency dataset.\n",
    "\n",
    "However, directional accuracy remained relatively low across all models, highlighting the inherent difficulty of short-term trend prediction in highly volatile financial markets. Overall, the findings suggest that hybrid models can improve numerical prediction accuracy, but reliable trend prediction remains a challenging task especially for cryptocurrencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d81e3-152d-4c15-8569-60e9853d6862",
   "metadata": {},
   "source": [
    "## 13. Limitations\n",
    "\n",
    "Despite achieving results, this project has several limitations that should be acknowledged. First, the models were trained on historical price data and technical indicators only. External factors such as macroeconomic events, news sentiment and geopolitical influences were not considered, even though they can have a significant impact on financial markets.\n",
    "\n",
    "Second, the evaluation was based on a single train–test split rather than a full walk-forward or rolling-window validation approach. While this simplifies the experimental design and reduces computational cost, it may limit the robustness of the conclusions.\n",
    "\n",
    "Third, directional accuracy remained relatively low, indicating that the models were better suited for price-level regression than for precise up/down trend prediction. This is a known challenge in financial forecasting, especially for highly volatile assets such as cryptocurrencies.\n",
    "\n",
    "Finally, the LSTM architecture used in this study was intentionally kept simple to maintain interpretability and computational feasibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2cc49c-7cb7-478d-89f6-64bf9cd867d0",
   "metadata": {},
   "source": [
    "## 14. Future Work\n",
    "\n",
    "Future research could extend this work in several directions. One possible improvement would be to incorporate additional data sources such as macroeconomic indicators from FRED, company fundamentals or news and sentiment analysis to capture external market drivers.\n",
    "\n",
    "Another extension would be to adopt a rolling-window or walk-forward validation strategy to better simulate real-world forecasting conditions and improve the robustness of model evaluation. Hyperparameter optimisation techniques such as grid search or Bayesian optimisation could also be applied to further improve model performance.\n",
    "\n",
    "More advanced deep learning architectures such as bidirectional LSTMs, GRU networks or attention-based models could be explored to better capture complex temporal dependencies. Additionally, reframing the problem as a classification task focused specifically on trend direction rather than price regression may improve directional accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9eb44a-7cb7-480d-8bf5-48665cd293e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
